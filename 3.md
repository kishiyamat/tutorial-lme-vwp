---
layout: post
title: 一般化線形混合モデル
description: LMEの解説ページ <a href="./">  🏠  <a><br>
    <a href="./2.html">⏪</a> 最短で乗り切ります。 <a href="./0.html">⏩</a>
---

これまでのところで [線形モデル(LM)][u1] と
[一般化線形モデル(GLM)][u2] を学んできました。
モデルの作成には `data.frame`と`formula`、`model` が必要だということ、
さらにGLMを組むには「観測できる値が従う確率分布」を`family`で指定すること、
そしてGLMの結果を解釈をしやすくするためには
リンク関数の理解が必要であることを学びました。
以下のコードの問、Q.1--3を見て復習しましょう。

```r
# LM
# Q1. data.frame, formula, model はどれでしょうか。
f = Reaction ~ Days
m = lm(f, sleepstudy)

# GLM
# Q2. なぜ family=binomial と指定しているのでしょうか。
f = Correct ~ Days
m = glm(f, sleepstudy, family=binomial

# Q3. Days と Estimate の値は Correct とどういう関係でしょうか。
summary(m)
> Coefficients:
>              Estimate Std. Error z value Pr(>|z|)  
> (Intercept)  0.83782    0.29216   2.868  0.00413 **  
> Days        -0.16017    0.05442  -2.943  0.00325 **
```

Q1はOKとして、上で `binomial` を指定する理由は LM の `Reaction` と異なり、
`Correct` は0/1で二項分布に従うからでした。
また結果の解釈には「リンク関数」が必要でした。
`binomial` の場合、`logit`関数がリンク関数だったことを思い出しましょう。
解釈に不安が残る場合は前回の内容を再度実行して
`p/(1-p) = exp(ax)*exp(b)` が何を示すのかを
思い出しましょう。

前回までのところまででLMを一般化させる方向は達成したので、
今回は「混合」の部分を足します。
とはいえ前回の内容に比べればだいぶ簡単で、
Rにおける縦線 `|` (バーと読みます) の役割を確認するだけです[^bar]。
まずは実データに触れながら <u>(i) 構造を表現する表記</u> を確認します。
そして<u>(ii) 構造的なノイズを扱うメリット</u> を抑え、
最後に <u>(iii) glmer を用いた一般化線形混合モデル</u> を
作成、分析していきます。

[^bar]: バーとかパイプとか呼ばれていますが、Rのパイプは別のものを示す場合が多いので、
    バーとしましょう。

## 構造を表現する表記

まずRにおける `|` の役割を確認するために、
とりあえず以下のコードを実行してプロットしてみましょう(**Submit**ボタンを押す)。
プロットの結果は右のペインの **Plots** を押すと別ウィンドウが開かれて、
拡大されて `Subject` ごとに `xyplot` が作れていることが確認できるかと思います。
どうしても拡大できない人は `xyplot`内の`#` を外してサブセットを見てみましょう。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    f = Reaction ~ Days | Subject
    xyplot(f, sleepstudy, type=c("p", "r"),
           # subset=Subject %in% c(370, 371)
           )
  </code>
  <code data-type="solution">
    f = Reaction ~ Days | Subject
    xyplot(f, sleepstudy, type=c("p", "r"),
           subset=Subject %in% c(370, 371))
  </code>
  <code data-type="sct">
    test_function("xyplot")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

前回 `xyplot` を使った時の `formula` は `f = Reaction ~ Days` だったのに対し、
`Subject` ごとのプロットは `| Subject` が足されている点に注意しましょう。
これを足すと `Subject` ごとに図が書かれたことから、
`| Subject` は 「`Subject` ごとに」という意味があることがわかると思います[^given]。
つまり、`Days` を被験者ごとに条件付けてプロットするときの `formula` に`|`が使えるのです。

[^given]: これは条件付確率 $P(X|Z)$ が「$Z$という文脈を与えた時の$X$の確率」
    を示すことと同じく、`Days` を被験者の文脈で条件付けていることと同じです。

条件付けられた `formula` を受けて `xyplot` が描画したのは被験者ごとの傾きや切片です。
これをモデリングでもできれば、
被験者ごとに傾きや切片をモデリングできそうなことは伝わるでしょうか。
ただ、図を見渡すと被験者ごとに傾きや切片の傾向に「全体的な効果」はあるものの、
個々のデータはバラバラです。
次は構造的なノイズを扱わず、
単に個々の傾きや切片といったパラメータを推定、分析することの問題点を見てみます。

## 構造的なノイズを扱うメリット

個人ごとの傾きや切片といったパラメータを推定、分析することは
最終的な目的ではありません。
被験者ごとのパラメータはバラバラなので、
それらの報告はとりとめのないものになってしまいます。
そうではなく、<u>全体的な効果</u> を「固定効果」、
個人差などの <u>構造的なノイズ</u> を「ランダム効果」として分離するのが
一般化線形混合モデルになります。

まずは最初の
「個人ごとの傾きや切片といったパラメータを推定、分析すること」
がいかに悪い方法であるかを実際に試して確認しましょう。
何が問題なのかすぐにわかります。
Rでは `lmList` という関数を使って
`Days | Subject`  つまり被験者ごとの`Days`の効果を求められます。
まずは先ほどと同様、とにかく以下のコードを実行してみましょう。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    f = Reaction ~ Days | Subject # 前回の範囲
    models = lmList(f, sleepstudy)
    summary(models)
  </code>
  <code data-type="solution">
    f = Reaction ~ Days | Subject
    models = lmList(f, sleepstudy)
    summary(models)
  </code>
  <code data-type="sct">
    test_function("summary")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

上を実行すると、以下のような被験者ごと(308, 309, ...)の切片`(Intercept)`と
`Days`の効果が求められたと思います。

```r
> Coefficients:
>    (Intercept) 
>     Estimate Std. Error  t value     Pr(>|t|)
> 308 244.1927   15.04169 16.23439 2.419368e-34
> 309 205.0549   15.04169 13.63244 1.067180e-27
> 310 203.4842   15.04169 13.52802 1.993900e-27
> :
>    Days 
>      Estimate Std. Error    t value     Pr(>|t|)
> 308 21.764702   2.817566  7.7246464 1.741840e-12
> 309  2.261785   2.817566  0.8027444 4.234454e-01
> 310  6.114899   2.817566  2.1702769 3.162541e-02
> :
```

確かにこれで`Reaction`に対する
「個人ごとの傾きや切片といったパラメータ」を推定できました。
でも分析や報告するときは「大体の人によっては効果ありました。」
のようなアバウトな物になってしまいそうです。
これに対して、もし全体的の効果 (固定効果) と
個人差などの構造的なノイズ (ランダム効果) を同時にモデリングできれば、
「全体的に効果ありました。個人差は織り込み済みです。」と言えますね。

これが「混合」、つまり固定効果とランダム効果を混ぜる動機になります。
最後に
<u>(i) 構造的なノイズをモデリングする方法</u> と
<u>(ii) Mixed の意味</u>、
<u>(iii) 一般化線形モデルの作り方</u>
の3点を次の節で確認しましょう。

## glmer を用いた一般化線形混合モデル

まず、Rにおける線形混合モデルの `model` には `lmer`があり[^lmer]、
`glmer` はこれを一般化(generalized)させた
一般化線形混合モデルの `model` です。
まずは `lmer`で 構造的なノイズをモデリングする方法を確認しましょう。

### 構造的なノイズをモデリングする方法、

線形モデルでは `f = Reaction ~ Days` で、
`f = Reaction ~ Days | Subject` だと固定効果を被験者ごとに推定してしまいます。
そうではなく、(一般化)線形混合モデルでは
`f = Reaction ~ Days  + (Days | Subject)`
と括弧でランダム効果を表現します。

[^lmer]: 例では`lmerTest`パッケージを使っています。

Reactionが正規分布に従っていると前提を起き[^normal]、
まずは`model` に`lmer`を使いましょう。
データは `sleepstudy`で
`formula` は`f = Reaction ~ Days  + (Days | Subject)` です。
後で試す `glmer`の時は見ないでこの`formula`を作れるようになりましょう。
以下のコードを実行してみましょう。

[^normal]: もちろん Gamma分布や対数正規分布過程してもいいが、
    その場合は glmer を使うことになるのと、
    Gamma分布の際は解釈が難しくなる。
    対数正規分布は試したが(glmerで`family=gaussian(link=log)`)、
    どうも切片のランダム効果が小さくなりすぎて
    警告を受けた。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lmerTest)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    f = Reaction ~ Days + (Days | Subject)
    m = lmer(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="solution">
    f = Reaction ~ Days + (Days | Subject)
    m = lmer(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="sct">
    test_function("summary")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

はい。モデリングできました。
さっきの list ではバラバラだったが、まとまっている。
`Days` が lmer の結果、
`(Days | Subject)` が `ranef(m)$Subject`の結果。
たすと `coef(m)$Subject` になる。

### Mixedの意味


<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lmerTest)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    f = Reaction ~ Days + (Days | Subject)
    m = lmer(f, sleepstudy)
    summary(m)
    # coef(m)$Subject
    # ranef(m)$Subject
  </code>
  <code data-type="solution">
    f = Reaction ~ Days + (Days | Subject)
    m = lmer(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="sct">
    test_function("summary")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

### 一般化線形モデルの作り方

はい。モデリングできました。
さっきの list ではバラバラだったが、まとまっている。
`Days` が lmer の結果、
`(Days | Subject)` が `ranef(m)$Subject`の結果。
たすと `coef(m)$Subject` になる。

もう少し具体的に370番のデータのモデリング
$Reaction = a \cdot Days + b + (a_{370} \cdot Days + b_{370})$ としている
coef(m)を見ると$a_{370}$が$ b_{370}$がと分かる。
$10 \cdot Days + 100 + (-1 \cdot Days + 100)$ と分かる。
これで固定効果を保ちつつ、被験者ごとのノイズを吸収している。
被験者ごとに専用の効果を足してあげる。
`Reaction ~ Days + (Days | Subject)` で
Days だけでなく被験者ごとのDaysの傾きの差を求めるのだ。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lmerTest)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    f = Reaction ~ Days + (Days | Subject)
    m = lmer(f, sleepstudy)
    summary(m)
    # coef(m)$Subject
    # ranef(m)$Subject
  </code>
  <code data-type="solution">
    f = Reaction ~ Days + (Days | Subject)
    m = lmer(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="sct">
    test_function("summary")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>


Yが従う分布を一般化してようやく「一般化線形混合モデル」になる。
お疲れ様でした。これで大体のデータの分析はできるようになる。
`Correct` と `Days` の関係をランダム効果ありで作成し、
`glmer` 関数を使って `family` は `Correct` が従う分布を選択してください。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    f = Correct ~ Days + (Days | Subject)
    m = glmer(f, sleepstudy, family=binomial)
    summary(m)
    # coef(m)$Subject
    # ranef(m)$Subject
  </code>
  <code data-type="solution">
    f = Correct ~ Days + (Days | Subject)
    glmer(f, sleepstudy, family=binomial)
    summary(m)
  </code>
  <code data-type="sct">
    test_function("summary")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

これが意味するところは

1. Correct は 固定効果 Days だけでなく
   構造的なランダムな効果も持っています。
   `Correct ~ Days + (Days | Subject)`
1. これらの列を含むデータは `sleepstudy` です。
1. ただし、Correct は二項分布に従います `family=binomial`
1. なお、一般化した混合効果モデルとして `glmer` を使います。

です。

## まとめ

これで統計のチュートリアルは終わりです。
線形モデルで要因の効果を検証し、
一般化して様々な分布に対応が可能であることを学び、
構造的なノイズを組み込める。

分析はできるようになった。
でも実験の組み方や要因の選び方のコツは反論できるようにすること。
いわゆる交互作用について。

「単語の長さ」が認知的不可に影響してるのでは？
ツッコミとして「単語の頻度なんじゃないの？」
`認知的不可 ~ 単語の長さ*単語の頻度` とモデルを組む。
そうすると「たしかにそうかもだけど、統計的には効果ありませんよ」と交わせる。
`認知的不可 ~ 単語の長さ` だけだと何も言えない。実験のやり直しになる。
構造的なノイズの気持ちもおなじ。
ツッコミとして「被験者によるんじゃないの？」
だからモデルに組み込んで「そうかもだけど、考慮しても効果はありましたよ」とかわせる。

相手の反論に対応するためには
「その話が本当ならXだよね。で、Yになってる？
Yになってないんでそれ違います」と持っていく。
あるいは持っていけないかもしれない。それはそれで進歩。
一番さけないと行けないのは、
その判断材料を相手に提示できないこと。
周りの人に 「交絡してないかな」 とチェックしてもらいましょう。
交絡してたら要因にいれましょう、それだけです。

[Extracting slopes for cases from a mixed effects model (lme4)][lme-ranef]

[lme-ranef]: https://stats.stackexchange.com/questions/122009/extracting-slopes-for-cases-from-a-mixed-effects-model-lme4
https://stats.stackexchange.com/questions/22988/how-to-obtain-the-p-value-check-significance-of-an-effect-in-a-lme4-mixed-mode

[back](./)

[u1]: ./1.html
[u2]: ./2.html
[u3]: ./3.html

---
