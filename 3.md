---
layout: post
title: 一般化線形混合モデル
description: LMEの解説ページ <a href="./">  🏠  <a><br>
    <a href="./2.html">⏪</a> 最短で乗り切ります。 <a href="./0.html">⏩</a>
---

これまでのところで [線形モデル(LM)][u1] と
[一般化線形モデル(GLM)][u2] を学んできました。
モデルを組むには `data.frame`と`formula`、`model` が必要だとうこと、
さらにGLMを組むには観測できる値が従う確率分布を`family`で指定すること、
そしてGLMの結果を解釈をしやすくするためには
リンク関数の理解が必要であることを学びました。
以下のコードを見て復習しましょう。

```r
# LM
f = Reaction ~ Days
m = lm(f, sleepstudy)

# GLM
f = Correct ~ Days
m = glm(f, sleepstudy, family=binomial)
summary(m)
# 前に Call などがあるが、解釈に必要なのは Coefficients(係数)
# 解釈時にはLink関数から p/(1-p) = exp(ax)*exp(b) になることを思い出す
> Coefficients:
>              Estimate Std. Error z value Pr(>|z|)  
> (Intercept)  0.83782    0.29216   2.868  0.00413 **  
> Days        -0.16017    0.05442  -2.943  0.00325 **
```

なぜ GLM で `binomial`かといえば、LM の`Reaction`と異なり、
`Correct`は0/1で二項分布に従うからでした。
また結果の解釈には「リンク関数」が必要でした。
`binomial`の場合、`logit`関数がリンク関数だったことを思い出しましょう。
解釈に不安が残る場合は前回の内容を再度実行して
`exp(ax)*exp(b)` や `p/(1-p)` が何を示すのかを
思い出しましょう。

前回までのところまででLMを一般化させる方向は達成したので、
今回は「混合」の部分を足しましょう。
とはいえ、前回の内容に比べればだいぶ簡単で、
Rにおける `|`(バー)の役割を確認するだけです[^bar]。
まずは実データに触れながら  <u>(i) 構造を表現する表記</u> を確認します。
そして<u>(ii) 構造的なノイズを扱うメリット</u> を抑え、
最後に <u>(iii) glmer を用いた一般化線形混合モデル</u> を実際に
作成、分析していきます。

[^bar]: バーとかパイプとか呼ばれていますが、Rのパイプは別のものを示す場合が多いので、
    バーとしましょう。

## 構造を表現する表記

まず、Rにおける `|` の役割を確認するために
以下のコードを実行(**Submit**ボタンを押下)してプロットしてみましょう。
プロットの結果は右のペインの **Plots** を押すと別ウィンドウが開かれて、
拡大されて `Subject` ごとに `xyplot` が作れていることが確認できるかと思います。
どうしても拡大できない人は `xyplot`内の`#` を外してサブセットを見てみましょう。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    f = Reaction ~ Days | Subject
    xyplot(f, sleepstudy, type=c("p", "r"),
           # subset=Subject %in% c(370, 371)
           )
  </code>
  <code data-type="solution">
    f = Reaction ~ Days | Subject
    xyplot(f, sleepstudy, type=c("p", "r"),
           subset=Subject %in% c(370, 371))
  </code>
  <code data-type="sct">
    test_function("xyplot")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

前回 `xyplot` を使った時の `formula` は `f = Reaction ~ Days` だったのに対し、
今回は `f = Reaction ~ Days | Subject` となっている点に注意しましょう。
違いは `| Subject` の部分で、これを足すと
`Subject` ごとに図が書かれたことから、
`| Subject` は 「`Subject` ごとに」という意味があることがわかると思います。
これは条件付確率 $P(X|Z)$ が「$Z$という文脈を与えた時の$X$の確率」
を示すことと同じく、`Days` を被験者の文脈で条件付けていることと同じです。
つまり、`Days` を被験者ごとに条件付けてモデリングすることを示すために
`|` を使っているのです。

その `formula` を受けて `xyplot` が描画したのは被験者ごとの傾きや切片です。
被験者ごとに傾きや切片の傾向は「全体的な効果」はあるものの、
それぞれはバラバラであることは伝わるでしょうか。
なんとなく、`|`を使って傾きや切片がモデリングできそうなことが伝わったでしょうか。
ただ、個人ごとに傾きや切片といったパラメータを推定、分析することが
「被験者のばらつきを考慮する」ことになるのでしょうか。

## 構造的なノイズを扱うメリット

個人ごとの傾きや切片といったパラメータを推定、分析することは
最終的な目的ではありません。
被験者ごとのパラメータはバラバラなので、
それらの報告はとりとめのないものになってしまいます。
そうではなく、<u>全体的な効果</u> を「固定効果」、
<u>個人という構造的なノイズ</u> を「ランダム効果」違いを分離するのが
一般化線形混合モデルになります。

まずは最初の
「個人ごとの傾きや切片といったパラメータを推定、分析すること」
がいかに悪いアイデアであるかを実際に試して確認しましょう。
何が問題なのかすぐにわかります。
Rでは `lmList` という関数を使って
`Days | Subject`  つまり被験者ごとの`Days`の効果を求められます。
まずは以下のコードを実行してみましょう。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    f = Reaction ~ Days | Subject # 前回の範囲
    models = lmList(f, sleepstudy)
    summary(models)
  </code>
  <code data-type="solution">
    f = Reaction ~ Days | Subject
    models = lmList(f, sleepstudy)
    summary(models)
  </code>
  <code data-type="sct">
    test_function("summary")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

上を実行すると、以下のような被験者ごと(308, 309, ...)の切片`(Intercept)`と
`Days`の効果が求められたと思います。

```r
> Coefficients:
>    (Intercept) 
>     Estimate Std. Error  t value     Pr(>|t|)
> 308 244.1927   15.04169 16.23439 2.419368e-34
> 309 205.0549   15.04169 13.63244 1.067180e-27
> 310 203.4842   15.04169 13.52802 1.993900e-27
> :
>    Days 
>      Estimate Std. Error    t value     Pr(>|t|)
> 308 21.764702   2.817566  7.7246464 1.741840e-12
> 309  2.261785   2.817566  0.8027444 4.234454e-01
> 310  6.114899   2.817566  2.1702769 3.162541e-02
> :
```

確かにこれで`Reaction`に対する
「個人ごとの傾きや切片といったパラメータ」を推定できました。
でも分析や報告するときは「大体の人によっては効果ありました。」
のようなアバウトな物になってしまいそうです。
これに対して、もし <u>全体的の効果 (固定効果)</u> と
<u>個人という構造的なノイズ (ランダム効果)</u>
を同時にモデリングできれば、
「全体的に効果ありました。個人差は織り込み済みです。」と言えますね。

これが「混合」、つまり混ざっている (Mixed) 構造的なノイズを組み込む
動機になります。
最後に
(i) 構造的なノイズモデリングする方法、
(ii) Mixed の意味
(iii) 一般化線形モデルの作り方
の3点を次の節で確認しましょう。

## glmer を用いた一般化線形混合モデル

Rで一般化線形混合モデルを作成するための関数には
`glmer`と`lmer`があります[^lmer]。
`glmer`のgは一般化(generalized)のgなので、
`lmer`は一般化されてない「線形混合モデル」を示すと分かります。
まずは `lmer`で 構造的なノイズモデリングする方法を確認しましょう。

### 構造的なノイズモデリングする方法、

線形モデルでは `f = Reaction ~ Days` で、
`f = Reaction ~ Days | Subject` だと固定効果を被験者ごとに推定してしまいます。
そうではなく、(一般化)線形混合モデルでは
`f = Reaction ~ Days  + (Days | Subject)`
と括弧でランダム効果を表現します。

[^lmer]: 例では`lmerTest`パッケージを使っています。

Reactionが正規分布に従っていると前提を起き[^normal]、
まずは`model` に`lmer`を使いましょう。
データは `sleepstudy`で
`formula` は`f = Reaction ~ Days  + (Days | Subject)` です。
後で試す `glmer`の時は見ないでこの`formula`を作れるようになりましょう。
以下のコードを実行してみましょう。

[^normal]: もちろん Gamma分布や対数正規分布過程してもいいが、
    その場合は glmer を使うことになるのと、
    Gamma分布の際は解釈が難しくなる。
    対数正規分布は試したが(glmerで`family=gaussian(link=log)`)、
    どうも切片のランダム効果が小さくなりすぎて
    警告を受けた。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lmerTest)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    f = Reaction ~ Days + (Days | Subject)
    m = lmer(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="solution">
    f = Reaction ~ Days + (Days | Subject)
    m = lmer(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="sct">
    test_function("summary")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

はい。モデリングできました。
さっきの list ではバラバラだったが、まとまっている。
`Days` が lmer の結果、
`(Days | Subject)` が `ranef(m)$Subject`の結果。
たすと `coef(m)$Subject` になる。

### Mixedの意味


<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lmerTest)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    f = Reaction ~ Days + (Days | Subject)
    m = lmer(f, sleepstudy)
    summary(m)
    # coef(m)$Subject
    # ranef(m)$Subject
  </code>
  <code data-type="solution">
    f = Reaction ~ Days + (Days | Subject)
    m = lmer(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="sct">
    test_function("summary")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

### 一般化線形モデルの作り方

はい。モデリングできました。
さっきの list ではバラバラだったが、まとまっている。
`Days` が lmer の結果、
`(Days | Subject)` が `ranef(m)$Subject`の結果。
たすと `coef(m)$Subject` になる。

もう少し具体的に370番のデータのモデリング
$Reaction = a \cdot Days + b + (a_{370} \cdot Days + b_{370})$ としている
coef(m)を見ると$a_{370}$が$ b_{370}$がと分かる。
$10 \cdot Days + 100 + (-1 \cdot Days + 100)$ と分かる。
これで固定効果を保ちつつ、被験者ごとのノイズを吸収している。
被験者ごとに専用の効果を足してあげる。
`Reaction ~ Days + (Days | Subject)` で
Days だけでなく被験者ごとのDaysの傾きの差を求めるのだ。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lmerTest)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    f = Reaction ~ Days + (Days | Subject)
    m = lmer(f, sleepstudy)
    summary(m)
    # coef(m)$Subject
    # ranef(m)$Subject
  </code>
  <code data-type="solution">
    f = Reaction ~ Days + (Days | Subject)
    m = lmer(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="sct">
    test_function("summary")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>


Yが従う分布を一般化してようやく「一般化線形混合モデル」になる。
お疲れ様でした。これで大体のデータの分析はできるようになる。
`Correct` と `Days` の関係をランダム効果ありで作成し、
`glmer` 関数を使って `family` は `Correct` が従う分布を選択してください。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    f = Correct ~ Days + (Days | Subject)
    m = glmer(f, sleepstudy, family=binomial)
    summary(m)
    # coef(m)$Subject
    # ranef(m)$Subject
  </code>
  <code data-type="solution">
    f = Correct ~ Days + (Days | Subject)
    glmer(f, sleepstudy, family=binomial)
    summary(m)
  </code>
  <code data-type="sct">
    test_function("summary")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

これが意味するところは

1. Correct は 固定効果 Days だけでなく
   構造的なランダムな効果も持っています。
   `Correct ~ Days + (Days | Subject)`
1. これらの列を含むデータは `sleepstudy` です。
1. ただし、Correct は二項分布に従います `family=binomial`
1. なお、一般化した混合効果モデルとして `glmer` を使います。

です。

## まとめ

これで統計のチュートリアルは終わりです。
線形モデルで要因の効果を検証し、
一般化して様々な分布に対応が可能であることを学び、
構造的なノイズを組み込める。

分析はできるようになった。
でも実験の組み方や要因の選び方のコツは反論できるようにすること。
いわゆる交互作用について。

「単語の長さ」が認知的不可に影響してるのでは？
ツッコミとして「単語の頻度なんじゃないの？」
`認知的不可 ~ 単語の長さ*単語の頻度` とモデルを組む。
そうすると「たしかにそうかもだけど、統計的には効果ありませんよ」と交わせる。
`認知的不可 ~ 単語の長さ` だけだと何も言えない。実験のやり直しになる。
構造的なノイズの気持ちもおなじ。
ツッコミとして「被験者によるんじゃないの？」
だからモデルに組み込んで「そうかもだけど、考慮しても効果はありましたよ」とかわせる。

相手の反論に対応するためには
「その話が本当ならXだよね。で、Yになってる？
Yになってないんでそれ違います」と持っていく。
あるいは持っていけないかもしれない。それはそれで進歩。
一番さけないと行けないのは、
その判断材料を相手に提示できないこと。
周りの人に 「交絡してないかな」 とチェックしてもらいましょう。
交絡してたら要因にいれましょう、それだけです。

[Extracting slopes for cases from a mixed effects model (lme4)][lme-ranef]

[lme-ranef]: https://stats.stackexchange.com/questions/122009/extracting-slopes-for-cases-from-a-mixed-effects-model-lme4
https://stats.stackexchange.com/questions/22988/how-to-obtain-the-p-value-check-significance-of-an-effect-in-a-lme4-mixed-mode

[back](./)

[u1]: ./1.html
[u2]: ./2.html
[u3]: ./3.html

---
