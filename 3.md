---
layout: post
title: 一般化線形混合モデル
description: LMEの解説ページ <a href="./">  🏠  <a><br>
    <a href="./2.html">⏪</a> 最短で乗り切ります。 <a href="./0.html">⏩</a>
---

これまで [線形モデル(LM)][u1] では
モデルの作成に `data.frame`と`formula`、`model` が必要だということを学びました。
さらに [一般化線形モデル(GLM)][u2] では
GLMを組むには「観測できる値が従う確率分布」を`family`で指定すること、
また結果を解釈をしやすくするためにはリンク関数の理解が必要であることを学びました。
以下のコードの問、Q.1--3を見て復習しましょう。

```r
# LM
# Q1. data.frame, formula, model はどれでしょうか。
f = Reaction ~ Days
m = lm(f, sleepstudy)

# GLM
# Q2. なぜ family=binomial と指定しているのでしょうか。
f = Correct ~ Days
m = glm(f, sleepstudy, family=binomial)

# Q3. Days と Estimate(-0.16017) の値は Correct とどういう関係でしょうか。
summary(m)
> Coefficients:
>              Estimate Std. Error z value Pr(>|z|)  
> (Intercept)  0.83782    0.29216   2.868  0.00413 **  
> Days        -0.16017    0.05442  -2.943  0.00325 **
```

Q1はOKとして、上で `binomial` を指定する理由は LM の `Reaction` と異なり、
`Correct` は0/1で二項分布に従うからでした。
また結果の解釈には「リンク関数」が必要でした。
`binomial` の場合、`logit`関数がリンク関数だったことを思い出しましょう。
解釈に不安が残る場合は前回の内容を再度実行して
`p/(1-p) = exp(ax)*exp(b)` が何を示すのかを
思い出しましょう。

前回までのところまででLMを一般化させる方向は達成したので、
今回は「混合」の部分を足します。
とはいえ前回の内容に比べればだいぶ簡単で、
Rにおける縦線 `|` (バーと読みます) の役割を確認するだけです[^bar]。
まずは実データに触れながら <u>(i) 構造を表現する記号</u> を確認します。
そして<u>(ii) 構造的なノイズを扱うメリット</u> を抑え、
最後に <u>(iii) glmer を用いた一般化線形混合モデル</u> を
作成、分析していきます。

[^bar]: バーとかパイプとか呼ばれていますが、Rのパイプは別のものを示す場合が多いので、
    バーとしましょう。

## 構造を表現する記号

まずRにおける `|` の役割を確認するために、
とりあえず以下のコードを実行してプロットしてみましょう(**Submit**ボタンを押す)。
プロットの結果は右のペインの **Plots** を押すと別ウィンドウが開かれて、
拡大されて `Subject` ごとに `xyplot` が作れていることが確認できるかと思います。
どうしても拡大できない人は `xyplot`内の`#` を外してサブセットを見てみましょう。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    f = Reaction ~ Days | Subject
    xyplot(f, sleepstudy, type=c("p", "r"),
           # subset=Subject %in% c(370, 371)
           )
  </code>
  <code data-type="solution">
    f = Reaction ~ Days | Subject
    xyplot(f, sleepstudy, type=c("p", "r"),
           subset=Subject %in% c(370, 371))
  </code>
  <code data-type="sct">
    test_function("xyplot")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

前回 `xyplot` を使った時の `formula` は `f = Reaction ~ Days` だったのに対し、
今回のプロットは `| Subject` が足されており、
`Subject`ごとに描画している点に注意しましょう。
これを足すと `Subject` ごとに図が書かれたことから、
`| Subject` は 「`Subject` ごとに」という意味があることがわかると思います[^given]。
つまり、被験者ごとに`Days`を条件付けてプロットしたいとき、
`formula` に `|` が使えるのです。

[^given]: これは条件付確率 $P(X|Z)$ が「$Z$という文脈を与えた時の$X$の確率」
    を示すことと同じく、`Days` を被験者の文脈で条件付けていることと同じです。

条件付けられた `formula` を受けとって
`xyplot` が描画したのは被験者ごとの傾きや切片です。
これをモデリングでもできれば、
被験者ごとに傾きや切片をモデリングできそうなことは伝わるでしょうか。
ただ図を見渡すと、傾きや切片の傾向に「全体的な効果」はあるものの、
被験者ごとのデータには「構造的なノイズ」があってバラバラです。
結論を言えば、データを「全体的な効果」と「構造的なノイズ」を明示的に混ぜて
モデリングするのが混合モデルになります。

次にデータを「全体的な効果」と「構造的なノイズ」を明示的に混ぜることの
メリットを知るため、これらを分けず
単に個々の傾きや切片といったパラメータを推定、
分析することの問題点を見てみます。
なお、個々に推定しない場合はただの「(一般化)線形モデル」になります。
こちらがまずい理由も最後に述べます。

## 固定効果とランダム効果に分けるメリット

個人ごとの傾きや切片といったパラメータを推定、分析することは
最終的な目的ではありません。
被験者ごとのパラメータはバラバラなので、
それらの報告はとりとめのないものになってしまいます。
そうではなく、<u>全体的な効果</u> を「固定効果」、
個人差などの <u>構造的なノイズ</u> を「ランダム効果」として分離するのが
一般化線形混合モデルになります。

まずは効果を分離せず、
最初の「個人ごとの傾きや切片といったパラメータを推定、分析すること」
がいかに悪い方法であるかを実際に試して確認しましょう。
何が問題なのかすぐにわかります。
Rでは `lmList` という関数を使って
`Days | Subject`  つまり被験者ごとの`Days`の効果を求められます。
まずは先ほどと同様、とにかく以下のコードを実行してみましょう。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    f = Reaction ~ Days | Subject # 前回の範囲
    models = lmList(f, sleepstudy)
    summary(models)
  </code>
  <code data-type="solution">
    f = Reaction ~ Days | Subject
    models = lmList(f, sleepstudy)
    summary(models)
  </code>
  <code data-type="sct">
    test_function("summary")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

上を実行すると、以下のような被験者ごと(308, 309, ...)の切片`(Intercept)`と
`Days`の効果が求められたと思います。

```r
> Coefficients:
>    (Intercept) 
>     Estimate Std. Error  t value     Pr(>|t|)
> 308 244.1927   15.04169 16.23439 2.419368e-34
> 309 205.0549   15.04169 13.63244 1.067180e-27
> 310 203.4842   15.04169 13.52802 1.993900e-27
> :
>    Days 
>      Estimate Std. Error    t value     Pr(>|t|)
> 308 21.764702   2.817566  7.7246464 1.741840e-12
> 309  2.261785   2.817566  0.8027444 4.234454e-01
> 310  6.114899   2.817566  2.1702769 3.162541e-02
> :
```

確かにこれで`Reaction`に対する
「個人ごとの傾きや切片といったパラメータ」を推定できました。
でも分析や報告するときは「大体の人によっては効果ありました。」
のようなアバウトな物になってしまいそうです。
これに対して、もし固定効果 (全体的な効果) と
ランダム効果 (個人差などの構造的なノイズ) を同時にモデリングできれば、
「全体的に効果ありました。個人差は織り込み済みです。」と言えますね。

これが「混合」、つまり固定効果とランダム効果を
明示的に混ぜる動機になります。
最後に
<u>(i) 構造的なノイズをモデリングする方法</u> と
<u>(ii) Mixed の意味</u>、
<u>(iii) 一般化線形モデルの作り方</u>
の3点を次の節で確認しましょう。

## glmer を用いた一般化線形混合モデル

まず、Rにおける線形混合モデルの `model` には `lmer`があり[^lmer]、
`glmer` はこれを一般化(generalized)させた
一般化線形混合モデルの `model` です。
まずは `lmer`で 構造的なノイズをモデリングする方法を確認しましょう。

### 構造的なノイズをモデリングする方法

線形モデルでは `f = Reaction ~ Days` で、
`f = Reaction ~ Days | Subject` だと効果を被験者ごとに推定してしまいます。
そうではなく、(一般化)線形混合モデルでは
`f = Reaction ~ Days  + (Days | Subject)`のように、
<u>括弧でランダム効果を表現</u>します。
Reactionが正規分布に従っていると前提を起き[^normal]、
まずは`model` に`lmer`を使いましょう。

[^lmer]: `lmerTest`パッケージを使えば*p*値も出せます。

データは `sleepstudy`で
`formula` は`f = Reaction ~ Days  + (Days | Subject)` です。
後で試す `glmer`の時はこの`formula`を見ないで作れるようになりましょう。
なお、この `formula` の意味は、
固定効果 `Days` に加えて `Subject` ごとの `Days` もランダム効果として
モデリングして、という意味です。
ここでの「ランダム効果」の意味は次の節で見ますので、
とりあえず以下のコードを実行してみましょう。

[^normal]: もちろん Gamma分布や対数正規分布過程してもいいが、
    その場合は glmer を使うことになるのと、
    Gamma分布の際は解釈が難しくなる。
    対数正規分布は試したが(glmerで`family=gaussian(link=log)`)、
    どうも切片のランダム効果が小さくなりすぎて
    警告を受けた。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4);
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    f = Reaction ~ Days + (Days | Subject)
    m = lmer(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="solution">
    f = Reaction ~ Days + (Days | Subject)
    m = lmer(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="sct">
    test_function("summary")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

さきほどの `lmList` では個人ごとにモデリングしたためバラバラでしたが、
今回のモデルの `summary` では `Fixed effects` と `Random effects` があり、
全体的な効果は `Fixed effects` 側が持っています。
`Fixed effects` の `Days` が `10.467` であることから、
1日増えると反応時間が10.467増えることがわかります。
そしてこの効果は `Subject` の効果も
`Random effects` でモデリングしてます。

`lmList` であった個人ごとのバラつきは、
つまり構造的なノイズは `Random effects` がモデリングしてます。
込み入った話になるのですが、
この「バラバラ感」は `Random effects` の `Std.Dev` で確認できます。
`(Intercept)` が平均 `24.740` ばらついていて、
`Days` の効果が平均 `5.922` ばらついていることからわかります。

つまり結果は以下のように解釈できます。
まず、`Fixed effects` の `Days` が `10.467` であることから、
1日増えると反応時間が10.467増えることがわかります。
ただし、その増え具合は被験者で平均 `5.922` 程度ばらつく、
というものです。
切片も同様で、基本は `251.405` だけれども
被験者で平均 `24.740` 程度ばらつくよ、
という解釈です。

```
Random effects:
 Groups   Name        Variance Std.Dev. Corr
 Subject  (Intercept) 612.09   24.740       
          Days         35.07    5.922   0.07
 Residual             654.94   25.592       
Number of obs: 180, groups:  Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  251.405      6.825   36.84
Days          10.467      1.546    6.77
```

次にランダム効果を確認する方法を述べます。
結果で報告する内容ではないので飛ばしてもらっても結構ですが、
知っておいたほうがモデルの理解は深まると思います。

### ランダム効果の実体

`Random effects` の内訳は
作成したモデルを `ranef(m)` という
名前そのまんまな関数に入れるとわかります。
以下のコードを実行してみてください。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    f = Reaction ~ Days + (Days | Subject)
    m = lmer(f, sleepstudy)
    ranef(m)$Subject
  </code>
  <code data-type="solution">
    f = Reaction ~ Days + (Days | Subject)
    m = lmer(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="sct">
    test_function("summary")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

すると、以下のように被験者ごとのランダム効果が出たと思います。

```
$Subjects
    (Intercept)        Days
308   2.2585654   9.1989719
309 -40.3985770  -8.6197032
310 -38.9602459  -5.4488799
330  23.6904985  -4.8143313
:
```

例えば308番のデータを用いて式を書くと、
$a \cdot Days + b + (a_{308} \cdot Days + b_{308})$ となることになります。
少し式を変えると、
$(a+a_{308}) \cdot Days + (b+b_{308})$ とも言えますね。
先ほどの固定効果を考えると、
$(10.467+9.1989719) \cdot Days + (251.405+2.2585654)$
が $Reaction_{308}$ の推定値になります。

さて、ここで確認問題です。
`ranef(m)` は被験者ごとのランダム効果を示し、
固定効果(`fixef`としましょう)は `summary`の`Fixed effects` にあります。
モデルの係数は`coef(m)` で確認でき、`10.467+9.1989719` や `251.405+2.2585654`、
つまり固定効果とランダム効果を足したものが被験者ごとの係数になります。
`fixef+ranef(m)=coef(m)` となるのですが、`coef(m)-ranef(m)`はどうなるでしょうか。

上の答えに納得できれば、
固定効果とランダム効果、係数の関係を理解していることになります。
最後に `lmer` を一般化させた `glmer` でモデル作成、分析をしてみましょう。

### 一般化線形モデルの作り方

前節では `Reaction` が正規分布に従うという仮定を置きましたが、
その仮定は `Correct` では成り立ちません。
Y が従う分布を一般化し、固定効果とランダム効果を混合して
ようやく「一般化線形混合モデル」になります。
これで大体のデータは分析できるようになります。
`Correct` と `Days` の関係をランダム効果ありで作成し、
`glmer` 関数を使ってモデリングしましょう。
なお、`family` は `Correct` が従う分布を選択してください。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    f = Correct ~ Days + (Days | Subject)
    m = glmer(f, sleepstudy, family=binomial)
    summary(m)
  </code>
  <code data-type="solution">
    f = Correct ~ Days + (Days | Subject)
    m = glmer(f, sleepstudy, family=binomial)
    summary(m)
  </code>
  <code data-type="sct">
    test_function("summary")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

これで一般化線形混合モデルを作れるようになりました。
分析、報告の内容は前回と同じになります。

## まとめ

これで統計のチュートリアルは終わりです。
線形モデルで要因の効果を検証し、
一般化して様々な分布に対応が可能であることを学び、
構造的なノイズを組み込めるようになりました。
今回は `Subjects` だけでしたが、
利用したアイテムや環境などもランダム効果に組み込めます。

ただ、今回のチュートリアルでは
実験の組み方や要因の選び方に関しては全く触れていません。
ここは指導教官や先輩に事前に相談しましょう。
その研究で何をしたいのかが一番大切で、
あくまでも統計はツールです。
このチュートリアルを通じて読める論文が増えたり、
できる実験が増えたりしたなら幸いです。

<!--
[Extracting slopes for cases from a mixed effects model (lme4)][lme-ranef]
[lme-ranef]: https://stats.stackexchange.com/questions/122009/extracting-slopes-for-cases-from-a-mixed-effects-model-lme4
https://stats.stackexchange.com/questions/22988/how-to-obtain-the-p-value-check-significance-of-an-effect-in-a-lme4-mixed-mode
-->

[back](./)

[u1]: ./1.html
[u2]: ./2.html
[u3]: ./3.html

---
