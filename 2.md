---
layout: post
title: 一般化線形モデル
description: LMEの解説ページ
    <a href="./">  🏠  <a>
---

[前回][u1] はチュートリアルのモチベーションとゴール、
そして線形モデルをつくりました。
またRでモデルを作るには `data.frame`, `formula`, `model` が必要だとも述べました。
今回は前回で述べたゴール、「直線以外の関係 に一般化させる」
について取り組んでいきます。
もう一度モチベーションを振り返りましょう。

まず前回の $y = ax + b$ は `lm` でモデルを作成できますが、
これは $y$ が要因に対して直線の関係にあることや負の値を取れることを仮定してました。
したがって、$y$ に範囲の指定がある場合に不適切なモデルとなります。
そこで直線以外も扱えるよう一般化したのが「<u>一般化</u>線形モデル」である、
という話でした。

この一般化線形モデルを理解するため、
まずは実データに触れながら <u>(i) 線形モデルを使うことの問題 </u> を確認します。
そして <u>(ii) 問題を解決するための「リンク関数」という概念 </u> を抑え、
最後に <u>(iii) glm を用いた一般化線形モデル </u> を実際に作成してみます。
<!--
GLMの説明にはよく「ログオッズ」という表現が出てくるのですが、
そもそも「オッズ」がピンとこないのでそこら辺もケアします。
-->  

## 直線の当てはめで起きそうな問題

まずは直線の問題点を見るために `xyplot()` を使いましょう。
前回の `sleepstudy` に `Correct` という「回答の正解/不正解(1/0)」を追加しました。
今回は `Days` が `Correct` を説明するかを検証するので、
以下の `f` に `formula` を作成してください。
可視化のしやすさのため `data.frame` は 350番の被験者データ(`sleepstudy_350`) を使います。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
    sleepstudy_350 = subset(sleepstudy, Subject==350)
  </code>
  <code data-type="sample-code">
    # f = Reaction ~ Days # 前回の範囲
    f = 
    # プロット(p)と回帰(r)の直線も描画
    xyplot(f, sleepstudy_350, type=c("p", "r"))
    # 余裕があれば `lm` を用いた回帰分析も確認
    # lm(f, sleepstudy_350)
  </code>
  <code data-type="solution">
    f = Correct ~ Days
    xyplot(f, sleepstudy_350, type=c("p", "r"))
  </code>
  <code data-type="sct">
    test_function("xyplot")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

<!--
TODO: もうちょっとくわしく
-->

当てはめられた傾きが右肩下がりなので、
日にちが増すほど正解が減ることは分かります。
しかし `Days` によっては 0--1 の範囲を超えてしまいそうだ、
ということも分かると思います。
`lm` を用いた回帰分析をした結果からも
切片は1を超えており `Days` が0
の時におかしなことになります。
この問題を抽象化すると、
「$Y = ax + b$ の $Y$ に範囲の制限があるとき、
直線の当てはめが不適切になる」
ということになります。

## GLMの基本要素

「範囲指定があるときに直線の当てはめをすると範囲外に飛びだしてしまう」
という問題に対応するため、
(i) 確率分布
(ii) 線形予測子
(iii) リンク関数
という概念を抑えていきます。

<!--
実際に推論する対象をずらす. ログオッズを推論する
まず確率分布に従うという過程で 0から1のpを考える。
ただ、解釈としては p ~ logistic(ax+b) もある。
ただ、logit(y) ~ ax+b が実際の対象になる
logit(y) の意味を考える
確率分布と線形予測子の関係
Y~確率分布~ax+b
-->


### 確率分布

線形モデルの $ax+b$ が直線である以上、
傾きが0でない限りいつかは $Y $の範囲を飛び出します。
そこでまず、
問題一つを与えた時の正答数 $Y$ が「二項分布」に従う場合を考えます。
この二項分布は確率 $p$ で現れる事象が
$size$回のうちに起こる回数を確率として表現します。
話が抽象的なので手を動かしていきましょう。

問題を正答できる確率 $p$ が0.8だったとして、
$size$ が1の二項分布を考えてみましょう。
これは「1回の試行で成功確率が0.8の時、何回成功するか」という分布です。
そもそも1回の試行なので、成功する回数は0か1ですね。
試しに100回二項分布に0と1を出させてみす。
`rbinom(p=0.8, size=1, n=100)` の結果を `y` に格納して、
`hist(y)` としてみましょう。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
  </code>
  <code data-type="sample-code">
    y =  # edit here
    hist()  # edit here
  </code>
  <code data-type="solution">
    y = rbinom(p=0.8, size=1, n=100)
    hist(y)
  </code>
  <code data-type="sct">
    test_function("hist")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
  use rbinom and hist functions
  </div>
</div>

0が少なく1が多い結果になりました[^binom]。
つまり、確率0.8の現象が1回のうちに起こる回数(0/1)は
「0の場合が少なく1の場合が多い」という分布になりそうです。
このように $Y$ の分布が確率 $p$ とサイズ$size$の二項分布に従うことを
$Y \sim \textrm{Binomial}(p, size)$
と表現します。

[^binom]: 一度 R Console に `y` と打ってみると
    `rbinom(p=0.8, size=1, n=100)` の結果を見れます。

さて、上の "Histgram of y" から推定すると
 $p$ は0.1と0.9、どちらが尤もらしいでしょうか。
おそらく0.9の方が尤もらしいと感じると思います。
つまり適当に複数のpの尤もらしさを比較して
最も尤もらしいpとなるまで繰り返せばデータからpは推定可能です。
このような最尤パラメータの推定を「最尤推定」と呼びます。
また推定ごとに$p$の値はぶれるので、
そのブレをそのまま$p$の値のばらつきと考えられます。

ここで仮に $p=ax+b$ が成り立つなら
適当に $a$ や $b$ を動かして $a$ や $b$ を最尤推定できるはずです。
そして $a$ がわかればモデリングの目的の一つである
「要因の大きさを知ること」が達成できます。
ただ $p$ は確率なので0--1の値を取るのに対し、
$ax+b$ が直線なのでその範囲を超えてしまうので
$p=ax+b$ とは表現できません。
この問題を次の節で考えます。

<!--
必要な概念を理解する
1. logistic
1. logit
1. rbinom
ただ、回帰の対象は結局ログオッズ
-->
### 確率分布と線形予測子

確かに $p=ax+b$ とは表現できないのは事実です。
しかし $ax+b$ の結果(実数)を必ず 0--1 の間に収めてくれる関数に
$\textrm{logistic}$関数があります。
先ほど $Y$ を見て適当に $p$ を動かして
最尤の $p$ を決めるという話をしたのですが、
$p=\textrm{logistic}(ax+b)$が成り立つなら
適当に $a$ や $b$ を動かして $a$ や $b$ を決められるはずです[^simple]。
そして $a$ がわかればモデリングの目的の一つである
「要因の大きさを知ること」が達成できます。

[^simple]: 厳密にはf(x)が短調増加の関数でないといけません。
    また、aやbを動かすイメージがつかない場合は一旦aを0だと考えると、
    ただの p=f(b) になりますよね。bが増えるときは必ずpが増えるので、
    それはpを動かして調整しているのと同じことになります。

ここで一旦 $ax+b$ を `lp` (linear predicor, 線形予測子) として、
`lp` の結果が0--1の外、例えば -4 から 4 の値を取るケースを見てみましょう。
そして `logistic` が各値を 0から1 に変換する形を見ます。
R では `lp = -4:4` とすれば `lp` に -4から4 の整数を格納してくれます。
この `lp` を `logistic` に与えた結果を `p` として `plot` しましょう[^logistic]。

[^logistic]: ちなみに `logistic` は以下のように定義できます。
    ```r
    logistic = function(x) {1 / (1 + exp(-x))}
    ```
    今回の目標から考えると関数の作成は蛇足ですが、
    Don't Repeat Yourself (DRY) という概念も
    本当はお伝えしたい気持ちです。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    logistic = function(x) {1 / (1 + exp(-x))}
  </code>
  <code data-type="sample-code">
    lp = # -4から4までの整数を作成 (ax+bの結果)
    p = # logistic()にlpを与えた結果をpに格納
    plot(x=lp, y=p, type="l") # "l" for line
  </code>
  <code data-type="solution">
    lp = -4:4
    p = logistic(lp)
    plot(x=lp, y=p, type="l")
  </code>
  <code data-type="sct">
    test_function("plot")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
  </div>
</div>

$\textrm{logistic}$ が実数を 0--1 の間に収めてくれそうなことを
確認できましたか[^sigmoid]。
これで $p=\textrm{logistic}(ax+b)$ が成り立つので、 
$\textrm{logistic}$ 経由で
$ax+b$ のパラメータを最尤推定できます。

[^sigmoid]: ちなみに sigmoid の意味は「sっぽい」です。
    アンドロイドとか ALife のボイド(boid: bird-oid)
    も同じ語源です。

<!--
ちなみに $\textrm{logistic}$ は実数を0-1に変換しますが、
これは「実数を確率の値に変換してくれる」とも解釈できます。
つまり $Days$ が増えるほど $a \cdot Days + b$ の値は減り (まだ0-1ではない)、
そこで $\textrm{logistic} (a \cdot Days + b)$ とすると、
正答する確率が下がる (0-1に収まる) と変換してくれます。
-->

ここまでを振り返ると、データ $Y$ から $p$, それと
$p=\textrm{logistic}(ax+b)$ から $a$ と $b$ も最尤推定できそうです。
ただ、そこで推定された $a$ や $b$ の意味は何なんでしょうか。
例えば $b$が0の時、
$x$ (寝不足)が1日増えると正答確率$p$ は
$\textrm{logistic}(a)$ だけが増える、と解釈できます。
ただ解釈のたびに $\textrm{logistic}(ax + b)$ を計算するのは面倒です。
この問題を解決してくれるのが「リンク関数」です。

### リンク関数と解釈

解釈のたびに $\textrm{logistic}(ax + b)$ を計算するのが面倒なら、
$\textrm{logit}(\textrm{logistic}(ax+b)) = ax+b$ となる
$\textrm{logit}$関数を考えてみましょう。
つまり、$\textrm{logit}$ を $p = \textrm{logistic}(ax+b)$の両辺に当てると、
等号の関係を変えないまま $\textrm{logit}(p) = ax+b$ と書き換えられます。
そうすると、$x$ (寝不足)が1日増えると $a$分だけ $\textrm{logit}(p)$
が増すと言い換えられます。
もし $\textrm{logit}(p)$ 自体が解釈しやすければ
$\textrm{logit}(p)$ を計算せずに済みます。

先程と同様、$ax+b$ を `lp` として -4 から 4 を与え、
`logitic` に入れた結果を `p` としましょう。
R では等しさを `==` で確認できるので
`p == logistic(lp)` は全て `TRUE` を返します。
上のように `lp == logit(logistic(lp))` は成り立つのでしょうか。
また、 `logit(p) == lp` も正しいのでしょうか。
上のそれぞれが成り立つなら、
両辺の差は計算上の誤差より小さくなる
(`左辺-右辺 < 0.00001`) はずです。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    logistic = function(x) {1 / (1 + exp(-x))}
    logit = function(p) log({p / (1-p)})
  </code>
  <code data-type="sample-code">
    lp = -4:4
    p = logistic(lp) # lpを与えた結果をpに格納

    # **以下は実行してTRUEを確認するだけ**
    p - logistic(lp) < 0.000001
    logit(logistic(lp)) - lp  < 0.000001
    logit(p) - lp < 0.000001
  </code>
  <code data-type="solution">
    lp = -4:4
    tol = 0.000001  # 計算上の誤差
    p = logistic(lp) # にlpを与えた結果をpに格納
    p - logistic(lp) < tol
    logit(logistic(lp)) - lp  < tol
    logit(p) - lp < tol
  </code>
  <code data-type="sct">
    success_msg("Great job!")
  </code>
  <div data-type="hint">
  </div>
</div>

$\textrm{logistic}$ の結果を $\textrm{logit}$ が打ち消せること、
また $\textrm{logit}$ を $p = \textrm{logistic}(ax+b)$ の両辺に当てると、
等号の関係を変えないまま $\textrm{logit}(p) = ax+b$ となることを確認できましたか。
これで $x$(寝不足)が1日増えると$a$分だけ $\textrm{logit}(p)$ が増すと言えます。
最後に $\textrm{logit}(p)$ の実体を見ましょう。

正答確率を $p$ としたとき、$\textrm{logit}(p)$ は 
$\textrm{log}\frac{p}{1-p}$ と表現できます。
$\frac{p}{1-p}$ の部分は「オッズ」と呼ばれており、
正答確率 $p$ が誤答確率 $1-p$ に比べてどのくらい大きいかを行っています。
例えば $p$ が $1-p$ と同じなら$1$, 倍なら$2$になります。
つまり、ロジット関数はこのオッズの対数を取った値になります。

オッズの対数も分かりづらいのですが、
両辺に `exp` を与えれば対数を落とせます[^exp]。
つまり `exp(logit(p)) = exp(a*x + b)` とすると
`p/(1-p) = exp(a*x) * exp(b)` になります。
もし最尤推定の結果が $a=2$, $b=0$ だったら
$x$ が1増えると`exp(2*1) * exp(0)`、
つまりオッズ(正答確率/誤答確率)が7くらい増えると解釈できます。

[^exp]: logとexpの関係は 上の R Console で `exp(log(2))` とすれば
    logisticとlogitの関係と同じだとわかります。

ここまでの流れをまとめると以下になります。

1. $Y$ から「確率分布(例: $\textrm{Binomial}$)の $p$」 や
   「$ax+b$ の $a$ や $b$」は計算可能
1. しかし $p=ax+b$ とはならないので $p=\textrm{logistic}(ax+b)$ で最尤推定
1. 解釈しづらい $p = \textrm{logistic}(ax+b)$ ではなく
   $\textrm{logit}(p) = ax+b$ から $a$ の効果を解釈

一度用語を整理すると、
$Y$ が従う分布を確率分布と呼び、
確率分布はパラメータで定義されていました(例: 成功確率$p$)。
そして上の $ax+b$ は線形予測子と呼ばれ、
「確率分布 $p$ のパラメータと線形予測子」をつなぐのがリンク関数でした
(例: \textrm{logit})。
\textrm{logistic} はモデリングを可能にしてくれて、
リンク関数は解釈を容易にしてくれるのでした。

一つ前の「線形モデル」と比べると、
確率分布とリンク関数が加わったように見えますが、
基本的に気にするのは確率分布だけで大丈夫で、
リンク関数は「知っていると解釈のときに便利」程度です。
今回はこの確率分布に「二項分布」を仮定しましたが、
何が嬉しいのでしょうか。

実は一つ前の「線形モデル」は確率分布に正規分布を仮定していて、
今回は二項分布を仮定していました。
正規分布は任意の実数を対象としますが二項分布は0か1だけです。
他にも0からN(整数)の関係や、
実数だけども分布が偏っていて正規分布でないものなど、
様々な分布がありえます。
こうした様々な分布を一般化線形モデルは扱えるのです。

それでは最後に `glm` を使ってモデリングしてみましょう。

### glm を用いた一般化線形モデル

一旦これをモデリングしてみましょう。
`logistic` という関数はこちらで用意しておいたので
$Correct = \textrm{logistic}(a \cdot Days + b)$
を `formula` で表現して `lm` モデルに入れましょう。
ただ、$a, b$ は推定対象なので
`formula` には入れないことに注意しましょう。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    # f = Correct ~ Days  # Days を非線形に変換
    f = 
    m = lm(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="solution">
    f = Correct ~ logistic(Days)
    m = lm(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="sct">
    test_function("summary")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

切片はxが0の時、どれくらい1になりやすいかのバイアス。
つまり寝不足0なら普通は正答率が1ということ。
そしてDaysが1増えると何倍ミスしやすくなるかが傾きで
1増えると-0.45ということは1増えると

現状は0--1の値を求めて 0や1との差分を少なくしている。
理想は0か1を求めてあるべきパラメータを最適化したい。
誤差の求めかた: 0か1か。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
    logit = function(p) log(p/(1-p))
  </code>
  <code data-type="sample-code">
    # f = Correct ~ Days  # Days を非線形に変換
    f = 
    m = lm(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="solution">
    f = logit(Correct) ~ Days
    m = lm(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="sct">
    test_function("summary")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

実際に線を引いてみよう。
全体的に正答しやすい
逆関数。

$\textrm{logit}(Correct) = a Days + b$
でも同じ。今度は Correct を0--1の外を許してあげている。

そこから <u>2. 確率の値に基づいて正誤(0/1)が生成される</u>
という結果となります。






ただ、
これはつまり、



$Y(非直線) ~ F(ax+b)$

つまり、一旦別の関数を噛ませて

直線でない

y=ax+b ではなく y=f(ax+b) を考える。
yには0や1,
ax+bには200など。
これを0--1の値に収める関数;
一旦収めると y=1の時に 0.2だったら変.
y=0の時に 0.8 だったら変。
そういう感じで aやbの値を更新できる。


カーブして欲しい。
これは0--1の連続

ここまでをまとめると

[u1]: ./1.html
[u2]: ./2.html
[u3]: ./3.html

[back](./)

---
