---
layout: post
title: 一般化線形モデル
description: LMEの解説ページ
    <a href="./">  🏠  <a>
---

[前回][u1] はチュートリアルのモチベーションとゴール、
そして線形モデルをつくりました。
またRでモデルを作るには3つの要素が必要だとも述べました。
今回は前回で述べたゴール、
「直線以外の関係 に一般化させる」
について取り組んでいきます。
もう一度モチベーションを振り返りましょう。

まず前回の $y = ax_1 + b$ は `lm` でモデルを作成できますが、
これは $y$ が要因に対して直線の関係にあることや負の値を取れることを仮定してました。
なので $y$ が整数の場合や範囲の指定がある場合に不適切なモデルとなります。
そこで直線以外も扱えるよう一般化したのが「<u>一般化</u>線形モデル」である、
という話でした。

この一般化線形モデルを理解するため、
まずは実例のデータに触れながら <u>(i) 線形モデルを使うことの問題 </u> を確認します。
そして <u>(ii) 問題を解決するための「リンク関数」という概念 </u> を抑え、
最後に <u>(iii) glm を用いた一般化線形モデル </u> を実際に作成してみます。
<!--
GLMの説明にはよく「ログオッズ」という表現が出てくるのですが、
そもそも「オッズ」がピンとこないのでそこら辺もケアします。
-->  

## 直線の当てはめで起きそうな問題

まずは直線の問題点を見るために `xyplot()` を使いましょう。
前回の `sleepstudy` に `Correct` という「回答の正解/不正解(1/0)」を追加しました。
今回は `Days` が `Correct` を説明するかを検証するので、
以下の `f` に `formula` を作成してください。
可視化のしやすさのため `data.frame` は 350番の被験者データ(`sleepstudy_350`) を使います。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
    sleepstudy_350 = subset(sleepstudy, Subject==350)
  </code>
  <code data-type="sample-code">
    # f = Reaction ~ Days # 前回の範囲
    f = 
    # プロット(p)と回帰(r)の直線も描画
    xyplot(f, sleepstudy_350, type=c("p", "r"))
    # 余裕があれば `lm` を用いた回帰分析も確認
    # lm(f, sleepstudy_350)
  </code>
  <code data-type="solution">
    f = Correct ~ Days
    xyplot(f, sleepstudy_350, type=c("p", "r"))
  </code>
  <code data-type="sct">
    test_function("xyplot")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

当てはめられた傾きが右肩下がりなので、
日にちが増すほど正解が減ることは分かります。
しかしDays によっては0--1の範囲を超えてしまいそうだ、
ということも分かると思います。
`lm` を用いた回帰分析をした結果からも
切片は1を超えており Daysが0
の時におかしなことになります。
この問題を抽象化すると、
「$Y = ax + b$ の $Y$ に範囲の制限があるとき、
直線の当てはめが不適切になる」
ということになります。

## GLMの基本要素

「範囲指定があるときに直線の当てはめをすると範囲外に飛びだしてしまう」
という問題に対応するため、
(i) 確率分布
(ii) 線形予測子
(iii)
という概念を抑えていきます。

<!--
確率分布と線形予測子の関係
Y~確率分布~ax+b
-->

### 確率分布

線形モデルの $ax+b$ が直線である以上、
傾きが0でない限りいつかは$Y$の範囲を飛び出します。
そこでまず、問題を一つを与えた時の正答の数 $Y$ が
「二項分布」に従う場合を考えます。
二項分布は確率 $p$ で現れる事象が
$size$回のうちに起こる回数を確率として表現します。
話が抽象的なので手を動かしていきましょう。

問題を正答できる確率qが0.8だったとして、
sizeが1の二項分布を考えてみましょう。
これは「1回の試行で成功確率が0.8の時、何回成功するか」という分布です。
そもそも1回の試行なので、成功する回数は0か1ですね。
試しに100回二項分布に0と1を出させてみす。
`rbinom(p=0.8, size=1, n=100)` の結果を `y` に格納して、
`hist(y)` としてみましょう。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
  </code>
  <code data-type="sample-code">
    y =  # edit here
    hist()  # edit here
  </code>
  <code data-type="solution">
    y = rbinom(p=0.8, size=1, n=100)
    hist(y)
  </code>
  <code data-type="sct">
    test_function("hist")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
  use rbinom and hist functions
  </div>
</div>

0が少なく1が多い結果になりました[^binom]。
つまり、確率0.8の現象が1回のうちに起こる回数(0/1)は
「0の場合が少なく1の場合が多い」という分布になりそうです。
このように $Y$ の分布が確率pとサイズsizeの二項分布に従うことを
$Y \sim \textrm{Binomial}(p, size)$
と表現します。
この時点で$Y$が0/1の値を取る点はクリアしました。

[^binom]: 一度 R Console に `y` と打ってみると
    `rbinom(p=0.8, size=1, n=100)` の結果を見れます。

また、上の `y` の出力結果を見て $p$ がどの程度か推定できるでしょうか。
$p$ が0.1なのと0.9なの、上の y からするとどちらが尤もらしいでしょうか。
おそらく0.9の方が尤もらしいと感じると思います。
つまり適当にpを決めて、尤もらしいかをチェックして
最も尤もらしい、つまり最尤のpとなるまで繰り返せば
データからpは推定可能です。

これは p を ax+b と表現しても同じことです。
適当にaやbの値を変えるとpも変わるのですが、
その結果のpが尤もらしいかをチェックする作業を繰り返せば
aやbも推定可能できます。
ただ、pは確率なので0--1の値を取るのに対し、
$ax+b$ が直線なのでその範囲を超えてしまうのが問題です。

そこで $ax+b$ の結果を必ず 0--1 の間に収めてくれて、
さらに aやb の推定の邪魔にならないような変換`f`があったらどうでしょうか。
つまり一旦 $z=ax+b$ のような一時的な値を置いて、
そこに変換を$p = f(z)$と噛ませてp(0--1)とします。
zの上下がpの上下と連動するなら、
pの尤もらしさはzの尤もらしさと連動するので
最尤のaやbの推定の邪魔にはなりません。

次にそんな素敵な性質を持った関数 $\textrm{logistic}$ を考えてみます。
チェックするポイントは z を 0--1 におさめてくれる点です。
zの上下がpの上下と対応している点は省略します[^deriv]。

[^deriv]: logisticを微分して短調増加であることを示せばOKです。
    補足のノートに書いておきます。

<!--
必要な概念を理解する
1. logistic
1. logit
1. rbinom
ただ、回帰の対象は結局ログオッズ
-->

### 線形予測子

上の話をまとめると、
データyからpの値を推定できて、
本当はp=ax+bとしたい。
が、ax+bは直線なので
$ax+b$ の結果を必ず 0--1 の間に収めてくれる関数 `logistic`
を使って p = logistic(ax+b) としよう、
ということでした。
このax+b を線形予測子zと呼びます。
したがって p = logistic(z) の関係が成り立ちます。

本当に `logistic` は期待通りの挙動なのでしょうか。
上の `z` で0--1以外、例えば -4 から 4 の値を試しに見てみましょう。
以下、どのように $\textrm{logistic}$ が各値を 0--1 の間に変換してくれるのかを見ます。
R では `z = -4:4` とすれば -4 から 4 までの整数を `z` に格納してくれます。
この `z` を `logistic()` に与えた結果を `y` として `plot` しましょう[^logistic]。

[^logistic]: ちなみに `logistic` は以下のように定義できます。
    ```r
    logistic = function(x) {1 / (1 + exp(-x))}
    ```
    今回の目標から考えると関数の作成は蛇足ですが、
    Don't Repeat Yourself (DRY) という概念も
    本当はお伝えしたい気持ちです。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    logistic = function(x) {1 / (1 + exp(-x))}
  </code>
  <code data-type="sample-code">
    z = # edit here
    y = # edit here
    plot(x=z, y=y, type="l") # "l" for line
  </code>
  <code data-type="solution">
    z = -4:4
    y = logistic(z)
    plot(x=z, y=y, type="l")
  </code>
  <code data-type="sct">
    test_function("plot")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

しっかりと
この値を 0--1 の間に収めることが意味するところは
「実数を確率の値に変換してくれる」ということです。
つまり $Days$ が増えるほど $a \cdot Days + b$ の値は減り (まだ0--1ではない)、
そこで $\textrm{logistic} (a \cdot Days + b)$ とすると、
正答する確率が下がる (0--1に収まる) と変換してくれます。

### リンク関数

うえで `p = logit(z)`

一旦これをモデリングしてみましょう。
`logistic` という関数はこちらで用意しておいたので
$Correct = \textrm{logistic}(a \cdot Days + b)$
を `formula` で表現して `lm` モデルに入れましょう。
ただ、$a, b$ は推定対象なので
`formula` には入れないことに注意しましょう。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    # f = Correct ~ Days  # Days を非線形に変換
    f = 
    m = lm(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="solution">
    f = Correct ~ logistic(Days)
    m = lm(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="sct">
    test_function("summary")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

切片はxが0の時、どれくらい1になりやすいかのバイアス。
つまり寝不足0なら普通は正答率が1ということ。
そしてDaysが1増えると何倍ミスしやすくなるかが傾きで
1増えると-0.45ということは1増えると

現状は0--1の値を求めて 0や1との差分を少なくしている。
理想は0か1を求めてあるべきパラメータを最適化したい。
誤差の求めかた: 0か1か。


よく出てくる「ロジット関数」。
これはlog(p/(1-p))になる。
つまりlog(p)-log(1-p)になる。
log(p)とは
"1-p"は「起きない確率」
つまり、起きない

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
    logit = function(p) log(p/(1-p))
  </code>
  <code data-type="sample-code">
    # f = Correct ~ Days  # Days を非線形に変換
    f = 
    m = lm(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="solution">
    f = logit(Correct) ~ Days
    m = lm(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="sct">
    test_function("summary")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

実際に線を引いてみよう。
全体的に正答しやすい
逆関数。

$\textrm{logit}(Correct) = a Days + b$
でも同じ。今度は Correct を0--1の外を許してあげている。

そこから <u>2. 確率の値に基づいて正誤(0/1)が生成される</u>
という結果となります。






ただ、
これはつまり、



$Y(非直線) ~ F(ax+b)$

つまり、一旦別の関数を噛ませて

直線でない

y=ax+b ではなく y=f(ax+b) を考える。
yには0や1,
ax+bには200など。
これを0--1の値に収める関数;
一旦収めると y=1の時に 0.2だったら変.
y=0の時に 0.8 だったら変。
そういう感じで aやbの値を更新できる。


カーブして欲しい。
これは0--1の連続

ここまでをまとめると

[u1]: ./1.html
[u2]: ./2.html
[u3]: ./3.html

---
