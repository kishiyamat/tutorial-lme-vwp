---
layout: post
title: 一般化線形モデル
description: LMEの解説ページ
    <a href="./">  🏠  <a>
---

[前回][u1] はチュートリアルのモチベーションとゴール、
そして線形モデルをつくりました。
またRでモデルを作るには `data.frame`, `formula`, `model` が必要だとも述べました。
今回は前回で述べたゴール、「直線以外の関係 に一般化させる」
について取り組んでいきます。
もう一度モチベーションを振り返りましょう。

まず前回の $y = ax + b$ は `lm` でモデルを作成できますが、
これは $y$ が要因に対して直線の関係にあることや負の値を取れることを仮定してました。
したがって、$y$ に範囲の指定がある場合に不適切なモデルとなります。
そこで直線以外も扱えるよう一般化したのが「<u>一般化</u>線形モデル」である、
という話でした。

この一般化線形モデルを理解するため、
まずは実データに触れながら <u>(i) 線形モデルを使うことの問題 </u> を確認します。
そして <u>(ii) 問題を解決するための「リンク関数」という概念 </u> を抑え、
最後に <u>(iii) glm を用いた一般化線形モデル </u> を実際に作成してみます。
<!--
GLMの説明にはよく「ログオッズ」という表現が出てくるのですが、
そもそも「オッズ」がピンとこないのでそこら辺もケアします。
-->  

## 直線の当てはめで起きそうな問題

まずは直線の問題点を見るために `xyplot()` を使いましょう。
前回の `sleepstudy` に `Correct` という「回答の正解/不正解(1/0)」を追加しました。
今回は `Days` が `Correct` を説明するかを検証するので、
以下の `f` に `formula` を作成してください。
可視化のしやすさのため `data.frame` は 350番の被験者データ(`sleepstudy_350`) を使います。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
    sleepstudy_350 = subset(sleepstudy, Subject==350)
  </code>
  <code data-type="sample-code">
    # f = Reaction ~ Days # 前回の範囲
    f = 
    # プロット(p)と回帰(r)の直線も描画
    xyplot(f, sleepstudy_350, type=c("p", "r"))
    # 余裕があれば `lm` を用いた回帰分析も確認
    # lm(f, sleepstudy_350)
  </code>
  <code data-type="solution">
    f = Correct ~ Days
    xyplot(f, sleepstudy_350, type=c("p", "r"))
  </code>
  <code data-type="sct">
    test_function("xyplot")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

<!--
TODO: もうちょっとくわしく
-->

当てはめられた傾きが右肩下がりなので、
日にちが増すほど正解が減ることは分かります。
しかしDays によっては0--1の範囲を超えてしまいそうだ、
ということも分かると思います。
`lm` を用いた回帰分析をした結果からも
切片は1を超えており Daysが0
の時におかしなことになります。
この問題を抽象化すると、
「$Y = ax + b$ の $Y$ に範囲の制限があるとき、
直線の当てはめが不適切になる」
ということになります。

## GLMの基本要素

「範囲指定があるときに直線の当てはめをすると範囲外に飛びだしてしまう」
という問題に対応するため、
(i) 確率分布
(ii) 線形予測子
(iii) リンク関数
という概念を抑えていきます。

<!--
実際に推論する対象をずらす. ログオッズを推論する
まず確率分布に従うという過程で 0から1のpを考える。
ただ、解釈としては p ~ logistic(ax+b) もある。
ただ、logit(y) ~ ax+b が実際の対象になる
logit(y) の意味を考える
確率分布と線形予測子の関係
Y~確率分布~ax+b
-->


### 確率分布

線形モデルの $ax+b$ が直線である以上、
傾きが0でない限りいつかは$Y$の範囲を飛び出します。
そこでまず、問題を一つを与えた時の正答の数 $Y$ が
「二項分布」に従う場合を考えます。
二項分布は確率 $p$ で現れる事象が
$size$回のうちに起こる回数を確率として表現します。
話が抽象的なので手を動かしていきましょう。

問題を正答できる確率qが0.8だったとして、
sizeが1の二項分布を考えてみましょう。
これは「1回の試行で成功確率が0.8の時、何回成功するか」という分布です。
そもそも1回の試行なので、成功する回数は0か1ですね。
試しに100回二項分布に0と1を出させてみす。
`rbinom(p=0.8, size=1, n=100)` の結果を `y` に格納して、
`hist(y)` としてみましょう。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
  </code>
  <code data-type="sample-code">
    y =  # edit here
    hist()  # edit here
  </code>
  <code data-type="solution">
    y = rbinom(p=0.8, size=1, n=100)
    hist(y)
  </code>
  <code data-type="sct">
    test_function("hist")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
  use rbinom and hist functions
  </div>
</div>

0が少なく1が多い結果になりました[^binom]。
つまり、確率0.8の現象が1回のうちに起こる回数(0/1)は
「0の場合が少なく1の場合が多い」という分布になりそうです。
このように $Y$ の分布が確率pとサイズsizeの二項分布に従うことを
$Y \sim \textrm{Binomial}(p, size)$
と表現します。

[^binom]: 一度 R Console に `y` と打ってみると
    `rbinom(p=0.8, size=1, n=100)` の結果を見れます。

さて、上の Histgram of y から推定すると $p$ は0.1と0.9、どちらが尤もらしいでしょうか。
おそらく0.9の方が尤もらしいと感じると思います。
つまり適当に複数のpの尤もらしさを比較して
最も尤もらしいpとなるまで繰り返せばデータからpは推定可能です。
このような最尤パラメータの推定を「最尤推定」と呼びます。
また推定ごとにpの値はぶれるので、
そのブレをそのままpの値のばらつきと考えられます。

ここで仮に $p=ax+b$ が成り立つなら
適当に aやbを動かして aやbを最尤推定できるはずです。
そしてaがわかればモデリングの目的の一つである
「要因の大きさを知ること」が達成できます。
ただ p は確率なので0--1の値を取るのに対し、
$ax+b$ が直線なのでその範囲を超えてしまうので
$p=ax+b$ とは表現できません。
この問題を次の節で考えます。

<!--
必要な概念を理解する
1. logistic
1. logit
1. rbinom
ただ、回帰の対象は結局ログオッズ
-->
### 確率分布と線形予測子

確かに $p=ax+b$ とは表現できないのは事実です。
しかし、もし $ax+b$ の結果(実数)を必ず 0--1 の間に収めてくれるような
変換 `f` があったらどうでしょうか。
先ほど Y を見て適当に p を動かして
最尤の p を決めるという話をしたのですが、
$p=f(ax+b)$が成り立つなら
適当にaやbを動かして aやbを決められるはずです[^simple]。
そしてaがわかればモデリングの目的の一つである
「要因の大きさを知ること」が達成できます。

[^simple]: 厳密にはf(x)が短調増加の関数でないといけません。
    また、aやbを動かすイメージがつかない場合は一旦aを0だと考えると、
    ただの p=f(b) になりますよね。bが増えるときは必ずpが増えるので、
    それはpを動かして調整しているのと同じことになります。

そんな性質を持った関数 $\textrm{logistic}$ を以下に考えてみます。
ここで一旦 ax+b を 線形予測子(linear predicor) から `lp` として、
`lp` の結果が0--1の外、例えば -4 から 4 の値を取るケースを見てみましょう。
Rで手を動かしながら $\textrm{logistic}$ が各値を 0--1 の間に変換する形を見ます。
R では `lp = -4:4` とすれば -4 から 4 までの整数を `lp` に格納してくれます。
この `lp` を `logistic()` に与えた結果を `p` として `plot` しましょう[^logistic]。

[^logistic]: ちなみに `logistic` は以下のように定義できます。
    ```r
    logistic = function(x) {1 / (1 + exp(-x))}
    ```
    今回の目標から考えると関数の作成は蛇足ですが、
    Don't Repeat Yourself (DRY) という概念も
    本当はお伝えしたい気持ちです。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    logistic = function(x) {1 / (1 + exp(-x))}
  </code>
  <code data-type="sample-code">
    lp = # -4から4までの整数を作成 (ax+bの結果)
    p = # logistic()にlpを与えた結果をpに格納
    plot(x=lp, y=p, type="l") # "l" for line
  </code>
  <code data-type="solution">
    lp = -4:4
    p = logistic(lp)
    plot(x=lp, y=p, type="l")
  </code>
  <code data-type="sct">
    test_function("plot")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
  </div>
</div>

logistic が実数を 0--1 の間に収めてくれそうなことを確認できましたか[^sigmoid]。
これで$p=f(lp)$が成り立つので、
f 経由でlp, つまり ax+b のパラメータの最尤推定ができます。

[^sigmoid]: ちなみに sigmoid の意味は「sっぽい」です。
    アンドロイドとか ALife のボイド(boid: bird-oid)
    も同じ語源です。

ちなみにlogisticは実数を0--1に変換しますが、
これは「実数を確率の値に変換してくれる」とも解釈できます。
つまり $Days$ が増えるほど $a \cdot Days + b$ の値は減り (まだ0--1ではない)、
そこで $\textrm{logistic} (a \cdot Days + b)$ とすると、
正答する確率が下がる (0--1に収まる) と変換してくれます。

ここまでを振り返ると、
データYからp, それと
$p=logistic(ax+b)$ から aとbも最尤できました。
ただ、そこで推定されたaやbの意味は何なんでしょうか。
つまり、例えばx(寝不足)が1日増えるとpはlogistic(a)分だけ確率が増すのです。
まずlogistic(a)が分かりづらいですし、
解釈のたびにlogistic関数に入れるのは面倒ですよね。
この問題を解決してくれるのが「リンク関数」です。

### リンク関数

うえで `p = logistic(ax+b)` という話を上げましたが、
この `logistic(ax+b)` の結果をなかったコトにする関数、
つまり `f(logistic(ax+b)) = ax+b` となるような関数を考えてみましょう。
その関数を`p = logistic(ax+b)`の両辺に当てると、等号の関係を変えないまま
`f(p) = ax+b` と書き換えられます。
そうすると、x(寝不足)が1日増えるとa分だけf(p)が増すと言い換えられます。
この際、f(p)が解釈しやすいものだったら、pを考える必要はないので
いちいち計算しなくてすみます。

そんな性質を持った関数 $\textrm{logit}$ をいかに考えてみます。
先程と同様、
ax+b を 線形予測子`lp` として、-4 から 4 の値を取るケースを見ます。
それに対して logitic を適用した値をpとしましょう。
Rではひとしさのチェックを `==` で行えるので、
`p == logistic(lp)` は各値のひとしさをチェックします。
仮に`logit`が`logistic`を打ち消せるなら、
`lp == logit(logistic(lp))` はどうなるでしょうか。
また、`p == logistic(lp)` から
`lp == logit(p)` 、
つまり `logit(p) == lp` と言えますが
正しいのでしょうか。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    logistic = function(x) {1 / (1 + exp(-x))}
    logit = function(p) {p / (1-p)}
  </code>
  <code data-type="sample-code">
    lp = -4:4
    p = logistic(lp) # にlpを与えた結果をpに格納

    # **以下は実行してTRUEを確認するだけ**
    p == logistic(lp) # 上の定義のっま
    logit(p) == logit(logistic(lp)) # (1) 等号は不変
    logit(logistic(lp)) == lp # (2) 打ち消し
    logit(p) == lp # (1)と(2)から
  </code>
  <code data-type="solution">
    lp = -4:4
    p = logistic(lp) # にlpを与えた結果をpに格納
    p == logistic(lp) # 上の定義のっま
    logit(p) == logit(logistic(lp)) # (1) 等号は不変
    logit(logistic(lp)) == lp # (2) 打ち消し
    logit(p) == lp # (1)と(2)から
  </code>
  <code data-type="sct">
    success_msg("Great job!")
  </code>
  <div data-type="hint">
  </div>
</div>

logisticの結果をlogitが打ち消せること、
また logit を `p = logistic(ax+b)`の両辺に当てると、
等号の関係を変えないまま
`lgoit(p) = ax+b` となることを確認できましたか。
これで x(寝不足)が1日増えるとa分だけlogit(p)が増すと言い換えられます。
最後にlogit(p)の実体を見ましょう。

正答確率をpとしたとき、logitは $\textrm{log}\frac{p}{1-p}$ と
表現できます。
この $\frac{p}{1-p}$ はオッズとか呼ばれてますが、
要は誤答確率(1-p)に比べて正答確率pがどのくらい割合が大きいかを行っています。
同じなら1, 確率が倍なら2になります。
つまり、このオッズの対数を取ったのがロジット関数になります。

このロジット(対数オッズ)も分かりづらいので、
両辺にexpを与えて
`exp(logit(p)) = exp(ax+b)` を
`odd(p) = exp(ax) + exp(b)` としましょう。
そうすると、aが2でbが0だったらxが1増えるとexp(2*1+0)だけ
オッズ(成功する割合/失敗する割合)が増える
と解釈できます。

つまり、ここまでの流れをまとめると以下になります。

1. Yから確率分布(例: binomial)のpやax+b のaやbは最尤推定で求まる
1. しかし p=ax+b とはならないのでp=f(ax+b)となるような関数fを考える
1. しかし p=f(ax+b) だと aが解釈しづらいので、g(p) = ax+b となるようなgを考える

上の ax+b を線形予測子、 確率分布のパラメータpと
線形予測子をつなぐ g をリンク関数と呼び、
fはモデリングを可能にしてくれて、
リンク関数gは解釈を容易にしてくれるのでした。

一つ前の「線形モデル」と比べると、
確率分布とリンク関数が加わったように見えますが、
基本的に気にするのは確率分布だけで大丈夫で、
リンク関数は「知っていると解釈のときに便利」程度です。
今回はこの確率分布に「二項分布」を仮定しましたが、
何が嬉しいのでしょうか。

実は一つ前の「線形モデル」は確率分布に正規分布を仮定していて、
今回は二項分布を仮定していました。
正規分布は任意の実数を対象としますが二項分布は0か1だけです。
他にも0からN(整数)の関係や、
実数だけども分布が偏っていて正規分布でないものなど、
様々な分布がありえます。
こうした様々な分布を一般化線形モデルは扱えるのです。

それでは最後に `glm` を使ってモデリングしてみましょう。

### glm を用いた一般化線形モデル

一旦これをモデリングしてみましょう。
`logistic` という関数はこちらで用意しておいたので
$Correct = \textrm{logistic}(a \cdot Days + b)$
を `formula` で表現して `lm` モデルに入れましょう。
ただ、$a, b$ は推定対象なので
`formula` には入れないことに注意しましょう。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    # f = Correct ~ Days  # Days を非線形に変換
    f = 
    m = lm(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="solution">
    f = Correct ~ logistic(Days)
    m = lm(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="sct">
    test_function("summary")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

切片はxが0の時、どれくらい1になりやすいかのバイアス。
つまり寝不足0なら普通は正答率が1ということ。
そしてDaysが1増えると何倍ミスしやすくなるかが傾きで
1増えると-0.45ということは1増えると

現状は0--1の値を求めて 0や1との差分を少なくしている。
理想は0か1を求めてあるべきパラメータを最適化したい。
誤差の求めかた: 0か1か。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
    logit = function(p) log(p/(1-p))
  </code>
  <code data-type="sample-code">
    # f = Correct ~ Days  # Days を非線形に変換
    f = 
    m = lm(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="solution">
    f = logit(Correct) ~ Days
    m = lm(f, sleepstudy)
    summary(m)
  </code>
  <code data-type="sct">
    test_function("summary")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

実際に線を引いてみよう。
全体的に正答しやすい
逆関数。

$\textrm{logit}(Correct) = a Days + b$
でも同じ。今度は Correct を0--1の外を許してあげている。

そこから <u>2. 確率の値に基づいて正誤(0/1)が生成される</u>
という結果となります。






ただ、
これはつまり、



$Y(非直線) ~ F(ax+b)$

つまり、一旦別の関数を噛ませて

直線でない

y=ax+b ではなく y=f(ax+b) を考える。
yには0や1,
ax+bには200など。
これを0--1の値に収める関数;
一旦収めると y=1の時に 0.2だったら変.
y=0の時に 0.8 だったら変。
そういう感じで aやbの値を更新できる。


カーブして欲しい。
これは0--1の連続

ここまでをまとめると

[u1]: ./1.html
[u2]: ./2.html
[u3]: ./3.html

---
