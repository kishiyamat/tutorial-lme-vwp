---
layout: post
title: 一般化線形モデル
description: <a href="./">  🏠  </a><br>
    <a href="./1.html">⏪</a> 最短で乗り切ります。 <a href="./3.html">⏩</a>
---

[前回][u1] はチュートリアルのモチベーションとゴールを抑えました。
また線形モデルの作成を通じ、
Rでモデルを作る際には `data.frame`, `formula`, `model` が必要だとも述べました。
今回は「直線以外の関係に一般化させる」というゴールを主眼に取り組んでいきます。
もう一度このゴールに対するモチベーションを振り返りましょう。

まず前回の $y = ax + b$ は `lm` でモデルを作成できますが、
これは $y$ が要因に対して直線の関係にあることや
負の値を取れること(値に制限が無いこと)を仮定してました。
したがって、$y$ に範囲の指定がある場合に不適切なモデルとなります。
そこで直線以外も扱えるよう一般化したのが「<u>一般化</u>線形モデル」である、
という話でした。

この一般化線形モデルを理解するため、
まずは実データに触れながら <u>(i) 線形モデルを使う際の問題点</u> を確認します。
そして <u>(ii) 問題点を解決するための「リンク関数」という概念</u> を抑え、
最後に <u>(iii) glm を用いた一般化線形モデル</u> を実際に作成してみます。
<!--
GLMの説明にはよく「ログオッズ」という表現が出てくるのですが、
そもそも「オッズ」がピンとこないのでそこら辺もケアします。
-->  

## 直線の当てはめで起きそうな問題

まずは直線の問題点を見るために `xyplot()` を使いましょう。
前回のデータ `sleepstudy` に「回答の正解/不正解(1/0)」の列 `Correct` を追加しました。
今回は寝不足`Days` が`Correct` を説明するかを検証するので、
復習がてら `Days` と `Correct` の関係を `formula` として
`f` に与えて可視化しましょう。
可視化のしやすさのため、
`sleepstudy` は 350番の被験者データに限定しています[^subset]。

[^subset]: `formula` を使う部分では大抵 `subset` オプションがある。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    # f = Reaction ~ Days # 前回の範囲
    f = # TODO: ここを編集
    xyplot(f, sleepstudy,
           subset=Subject==350, # 350番に限定
           type=c("p", "r") # plot, regression
           )
    # 余裕があれば `lm` を用いた回帰分析も確認
    # lm(f, sleepstudy, subset=Subject==350)
  </code>
  <code data-type="solution">
    f = Correct ~ Days
    xyplot(f, sleepstudy,
           subset=Subject==350, # 350を指定
           type=c("p", "r") # plot, regression
           )
    lm(f, sleepstudy, subset=Subject==350)
  </code>
  <code data-type="sct">
    test_function("xyplot")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

<!--
TODO: もうちょっとくわしく
-->

当てはめられた回帰直線が右肩下がりなので、
`Days` が増すほど正解が減ることは分かります。
しかし4日目あたりの正答数0.8とはどういうことでしょうか。
また、`Days` によっては 0--1 の範囲を超えてしまいそうです。
`lm` を用いた回帰分析をした結果からも
切片は1を超えており `Days` が0
の時におかしなことになります。
したがって $Y = ax + b$ の当てはめでは
以下の問題が発生しうることを確認しましょう。
(もちろん、適切の場合もあります。)

1. $Y$ に範囲の制限があるとき(飛び出す)
2. $Y$ が整数であるとき(正解数0.8は意味不明)

## GLMの基本要素

範囲指定があるときに直線の当てはめをすると範囲外に飛びだす、
整数を取ってほしいのに小数点の値になってしまう、
などの問題に対応するため、以下の3つの概念を抑えていきます。

1. 確率分布
1. 線形予測子
1. リンク関数

どれも最初は抽象的でわかりづらく思えますが、
これが分かればGLMの考え方や結果の見方はマスターです。
おそらくRでもSPSSでも問題ないでしょう。
ただ、ここからは話が抽象的になるので、
手を動かしていきましょう。

<!--
実際に推論する対象をずらす. ログオッズを推論する
まず確率分布に従うという過程で 0から1のpを考える。
ただ、解釈としては p ~ logistic(ax+b) もある。
ただ、logit(y) ~ ax+b が実際の対象になる
logit(y) の意味を考える
確率分布と線形予測子の関係
Y~確率分布~ax+b
-->

### 確率分布

線形モデルの $ax+b$ が直線である以上、
傾きが0でない限りいつかは指定の範囲を飛び出します。
そこでまず、
問題一つを与えた時の正答数 $Y$ が「二項分布」に従う場合を考えます。
この二項分布は確率 $p$ で現れる事象が
$size$回のうちに起こる回数(x)を分布(y=確率)として表現します。
話が抽象的なので手を動かしていきましょう。

問題を正答できる確率 $p$ が0.8だったとして、
$size$ が1の二項分布を考えてみましょう。
これは「1回の試行で成功確率が0.8の時、X回成功する確率はYだ」という分布です。
そもそも1回の試行なので、成功する回数は0か1ですね。
試しに100回二項分布に0と1を出させてみす。
`rbinom(p=0.8, size=1, n=100)` の結果を `y` に格納して、
`hist(y)` としてみましょう。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
  </code>
  <code data-type="sample-code">
    y =  # edit here
    hist()  # edit here
  </code>
  <code data-type="solution">
    y = rbinom(p=0.8, size=1, n=100)
    hist(y)
  </code>
  <code data-type="sct">
    test_function("hist")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
  use rbinom and hist functions
  </div>
</div>

0が少なく1が多い結果になりました[^binom]。
つまり、確率0.8の現象が1回のうちに起こる回数(0/1)は
「1の場合のほうが起こりやすそうだ」という分布になりそうです。
このように $Y$ の分布が確率 $p$ とサイズ $size$ の二項分布に従うことを
$Y \sim \textrm{Binomial}(p, size)$
と表現します。
そしてこの時点で$Y$が離散かつ制限のある場合を表現できているのですが、
まだ $ax+b$ との関係が不明です。

[^binom]: 一度 R Console に `y` と打ってみると
    `rbinom(p=0.8, size=1, n=100)` の結果を見れます。

さて、上の "Histgram of y" から判断すると
$p$ は0.5と0.8、どちらが尤もらしいでしょうか。
おそらく0.8の方が尤もらしいと感じると思います。
つまり適当に「複数の $p$」のデータに対する尤もらしさを比較して
最も尤もらしい $p$ となるまで比較を繰り返せばデータから
ベストな$p$ は推定可能です。
このような最尤パラメータの推定を「最尤推定」と呼びます。
また推定ごとに $p$ の値はぶれるので、
そのブレをそのまま $p$ の値のばらつきと考えられます。
まだ $ax+b$ との関係が不明です。

ここでようやく $p=ax+b$ が成り立つと仮定しましょう。
そうすると、適当に $a$ や $b$ を変えて比較することで
$a$ や $b$ を最尤推定できるはずです。
そして $a$ がわかればモデリングの目的の一つである
「要因の大きさを知ること」が達成できます。
ただ $p$ は確率なので0--1の値を取るのに対し、
$ax+b$ は直線で範囲を超えてしまうので $p=ax+b$ とは表現できません。
この先送りにされた問題は次の節で考えます。

ここまでをまとめると以下になります。

1. $Y$の範囲が制限されている、値が離散であるべき、という問題は「確率分布」が解決
1. 手元のデータから確率分布のpは推定可能で $p=ax+b$ が成り立つなあら $a$ や $b$ 
   も推定可能
1. 実際には成り立たないので、推定のためにはもう一つ作業が必要

<!--
必要な概念を理解する
1. logistic
1. logit
1. rbinom
ただ、回帰の対象は結局ログオッズ
-->
### 確率分布と線形予測子

確かに $p=ax+b$ とは表現できないのは事実です。
しかし $ax+b$ の結果(実数)を必ず 0--1 の間に収めてくれる
「$\textrm{logistic}$関数」があります。
先ほど $Y$ を見て適当に $p$ を動かして
最尤の $p$ を決めるという話をしたのですが、
$p=\textrm{logistic}(ax+b)$が成り立つなら、
適当に $a$ や $b$ を動かして
範囲を飛び出さずに $a$ や $b$ を決められるはずです[^simple]。
そして $a$ がわかればモデリングの目的の一つである
「要因の大きさを知ること」が達成できます。

[^simple]: 厳密にはf(x)が短調増加の関数でないといけません。
    また、aやbを動かすイメージがつかない場合は一旦aを0だと考えると、
    ただの p=f(b) になりますよね。bが増えるときは必ずpが増えるので、
    それはpを動かして調整しているのと同じことになります。

ここで一旦 $ax+b$ を `lp` (linear predicor, 線形予測子) として、
`lp` の結果が0--1の外、例えば -4 から 4 の値を取るケースを見てみましょう。
そして `logistic` が-4から4の値をどのように 0 から1 に変換するかを見ます。
R では `lp = -4:4` とすれば `lp` に -4から4 の整数を格納してくれます。
この `lp` を `logistic` に与えた結果を `p` として `plot` しましょう[^logistic]。

[^logistic]: ちなみに `logistic` は以下のように定義できます。
    ```r
    logistic = function(x) {1 / (1 + exp(-x))}
    ```
    今回の目標から考えると関数の作成は蛇足ですが、
    Don't Repeat Yourself (DRY) という概念も
    本当はお伝えしたい気持ちです。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    logistic = function(x) {1 / (1 + exp(-x))}
  </code>
  <code data-type="sample-code">
    lp = # -4から4までの整数を作成 (ax+bの結果)
    p = # logistic()にlpを与えた結果をpに格納
    plot(x=lp, y=p, type="l") # "l" for line
  </code>
  <code data-type="solution">
    lp = -4:4
    p = logistic(lp)
    plot(x=lp, y=p, type="l")
  </code>
  <code data-type="sct">
    test_function("plot")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
  </div>
</div>

$\textrm{logistic}$ が実数(といっても-4から4)を
0--1 の間に収めてくれそうなことを
確認できましたか[^sigmoid]。
これで $p=\textrm{logistic}(ax+b)$ が成り立つので、 
$\textrm{logistic}$ 経由で
$ax+b$ のパラメータを最尤推定できます。

[^sigmoid]: ちなみに sigmoid の意味は「sっぽい」です。
    アンドロイドとか ALife のボイド(boid: bird-oid)
    も同じ語源です。

<!--
ちなみに $\textrm{logistic}$ は実数を0-1に変換しますが、
これは「実数を確率の値に変換してくれる」とも解釈できます。
つまり $Days$ が増えるほど $a \cdot Days + b$ の値は減り (まだ0-1ではない)、
そこで $\textrm{logistic} (a \cdot Days + b)$ とすると、
正答する確率が下がる (0-1に収まる) と変換してくれます。
-->

ここまでを振り返ると、データ $Y$ から「確率分布の$p$」,
それと $p=\textrm{logistic}(ax+b)$ から $a$ と $b$ も最尤推定できそうです。
ただ、そこで推定された $a$ や $b$ の解釈は困難です。
例えば $b=0$の時、
$x$ (寝不足)が1日増えると正答確率$p$ は
$\textrm{logistic}(a)$ だけが増える、と解釈できます。
このように解釈するたび $\textrm{logistic}(ax + b)$ を計算するのは面倒です。
この問題を解決してくれるのが「リンク関数」です。

### リンク関数と解釈

解釈のたびに $\textrm{logistic}(ax + b)$ を計算するのが面倒なら、
その計算がなかったことにしてくれる、
つまり $\textrm{logit}(\textrm{logistic}(ax+b)) = ax+b$ となる
「$\textrm{logit}$関数」を考えてみましょう。
ここで $\textrm{logit}$関数を
解釈の難しい $p = \textrm{logistic}(ax+b)$の両辺に当てると、
$\textrm{logit}(p) = ax+b$ と書き換えられます。
そうすると、$x$ (寝不足)が1日増えると $a$分だけ $\textrm{logit}(p)$
が増すと言い換えられます。
もし $\textrm{logit}(p)$ 自体が解釈しやすければ
$\textrm{logit}(p)$ を計算せずに済みます。

下では先程と同様、$ax+b$ を `lp` として -4 から 4 を与え、
`lp` を `logitic` に入れた結果を `p` としました。
上に述べたように `logit(logistic(lp)) == lp` は成り立つのでしょうか。
また、 `logit(p) == lp` も正しいのでしょうか。
そこで計算上の誤差を `0.000001` としたとき、
上のそれぞれが成り立つなら両辺の差は計算上の誤差より小さくなる
(`左辺-右辺 < 0.000001`) はずです。
以下は実行するだけなのですが、確認しましょう。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    logistic = function(x) {1 / (1 + exp(-x))}
    logit = function(p) log({p / (1-p)})
  </code>
  <code data-type="sample-code">
    lp = -4:4
    p = logistic(lp) # lpを与えた結果をpに格納

    # **以下は実行してTRUEを確認するだけ**
    logit(logistic(lp)) - lp  < 0.000001
    logit(p) - lp < 0.000001
  </code>
  <code data-type="solution">
    lp = -4:4
    tol = 0.000001  # 計算上の誤差
    p = logistic(lp) # にlpを与えた結果をpに格納
    logit(logistic(lp)) - lp  < tol
    logit(p) - lp < tol
  </code>
  <code data-type="sct">
    success_msg("Great job!")
  </code>
  <div data-type="hint">
  </div>
</div>

$\textrm{logistic}$ の結果を $\textrm{logit}$ が打ち消せること、
また $\textrm{logit}$ を $p = \textrm{logistic}(ax+b)$ の両辺に当てると、
等号の関係を変えないまま $\textrm{logit}(p) = ax+b$ となることを確認できましたか。
これで $x$(寝不足)が1日増えると$a$分だけ $\textrm{logit}(p)$ が増すと言えます。
$\textrm{logit}(p)$ の実体さえ分かれば推定したパラメータの意味が
解釈しやすくなります。

正答確率を $p$ としたとき、$\textrm{logit}(p)$ は 
$\textrm{log}\frac{p}{1-p}$ と表現できます。
$\frac{p}{1-p}$ の部分は「オッズ」と呼ばれており、
要は「正答確率 $p$ が誤答確率 $1-p$ に比べてどのくらい大きいか」を表現しています。
例えば $p$ が $1-p$ と同じなら$1$, 倍なら$2$になります。
つまり、ロジット関数はこのオッズの対数を取った値になります。

オッズの対数も分かりづらいのですが、
両辺に `exp` を与えれば対数を落とせます[^exp]。
つまり `exp(logit(p)) = exp(a*x + b)` とすると
`p/(1-p) = exp(a*x) * exp(b)` になります。
例えば、もし最尤推定の結果が $a=2$, $b=0$ だったら
$x$ が1増えると`exp(2*1) * exp(0)`、
つまりオッズ(正答確率/誤答確率)が7くらい増えると解釈できます。

[^exp]: logとexpの関係は 上の R Console で `exp(log(2))` とすれば
    logisticとlogitの関係と同じだとわかります。

ここまでの流れをまとめると以下になります。

1. <u>確率分布</u>とは観測したデータ $Y$ が従う分布で、
   $Y$の範囲が制限されている、値が離散であるべき、という問題を解決してくれる
   (例: 正答数や5段階評価なども二項分布)
1. 手元のデータから確率分布のパラメータ (例: 成功確率$p$) は最尤推定でき、
   また $p = \textrm{logit}(ax+b)$ と変換を挟めば $a$ や $b$ も最尤推定可能
1. $\textrm{logit}(ax+b)$の計算はめんどうだが
   $\textrm{logit}(p) = ax+b$ と<u>リンク関数</u>で書き換えることで
   最尤推定した $a$ の効果を容易に解釈可能

一つ前の「線形モデル」が $Y = ax+b$ だけで表現できていたのですが、
それと比べると新たに確率分布とリンク関数が加わっています。
ただ、実際にモデリングするときに気をつけるのは確率分布だけで大丈夫で、
リンク関数は「知っていると解釈のときに便利」程度です。
今回はこの確率分布に「二項分布」を仮定しましたが、
これのどこが「一般化」なのでしょうか。

実は一つ前の「線形モデル」は確率分布に正規分布を仮定していました。
GLMは確率分布に正規分布だけでなく今回のように二項分布も仮定できます。
他にも0以上の整数の分布(ポワソン分布)や、
0以上で偏っている分布(対数正規分布)など、
「指数型分布族(exponential <u>family</u>)」に属す様々な分布を扱えます。
このように $Y$ が従う様々な確率分布を一般化線形モデルは扱えるのです。
この扱える $Y$ の拡張こそが「一般化」になります。

それでは最後に `glm` を使ってモデリングして
一般化線形モデルの説明を終えます。

## glm を用いた一般化線形モデル

GLM でも`lm`と同様に `data.frame`, `formula`, `model` が必要で、
`formula` にはデータの列の関係を記述します。
`lm` と違う点は $Y$ が従う確率分布を `glm` 内で
`family=binomial` のように指定する点です。
リンク関数は `family=binomial` とした時点で
自動的に `logit` が指定されるので定義は不要です。
以下に `Correct` と `Days` の関係を `formula` に定義し、
`family` の指定をしましょう。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
    library(lattice); library(lme4)
    set.seed(43)
    # data
    rt = sleepstudy$Reaction
    logistic = function(x) {1 / (1 + exp(-x))}
    scale = function(x) (x-min(x))/(max(x)-min(x))
    ps = logistic(-5*scale(rt)+2)
    xs = as.integer(rbinom(ps, n=length(ps), size=1))
    sleepstudy$Correct = xs
  </code>
  <code data-type="sample-code">
    f = 
    m = glm(f, sleepstudy, family=)
    summary(m)
  </code>
  <code data-type="solution">
    f = Correct ~ logistic(Days)
    m = glm(f, sleepstudy, family=binomial)
    summary(m)
  </code>
  <code data-type="sct">
    test_function("summary")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

結果を格納した `m` のサマリーの `Coefficients` を見ると、
以下のようになっています。
`(Intercept)` 、つまり切片に対する `Estimate` は 0.83,
`Days` 、つまり要因に対する `Estimate` は -0.16となっています。
解釈の時に必要なのはリンク関数でしたね。
リンク関数を使うと $\textrm{logit}(p) = ax+b$ と表現でき、
つまりは `p/(1-p) = exp(a*x) * exp(b)` です。
ここで$x$ が1の時の $a$ の効果を知りたいときは $b=0$ として、
`exp(a*1) * exp(b)` を考えます。

<div data-datacamp-exercise data-lang="r">
  <code data-type="pre-exercise-code">
  </code>
  <code data-type="sample-code">
    a = -0.16
    b = 0.83
    odd = exp() * exp()  # p/(1-p)つまりoddsを計算
    print(odds)
  </code>
  <code data-type="solution">
    a = -0.16
    b = 0.83
    odd = exp(1*a) * exp(b)
    print(odd)
  </code>
  <code data-type="sct">
    test_function("print")
    success_msg("Great job!")
  </code>
  <div data-type="hint">
    前回は Reaction ~ Days を見ましたね。今回は Correct を見ましょう。
  </div>
</div>

これを


```r
> Coefficients:
>              Estimate Std. Error z value Pr(>|z|)  
> (Intercept)  0.83782    0.29216   2.868  0.00413 **  
> Days        -0.16017    0.05442  -2.943  0.00325 **
```


切片はxが0の時、どれくらい1になりやすいかのバイアス。
つまり寝不足0なら普通は正答率が1ということ。
そしてDaysが1増えると何倍ミスしやすくなるかが傾きで
1増えると-0.45ということは1増えると

現状は0--1の値を求めて 0や1との差分を少なくしている。
理想は0か1を求めてあるべきパラメータを最適化したい。
誤差の求めかた: 0か1か。

実際に線を引いてみよう。
全体的に正答しやすい
逆関数。

$\textrm{logit}(Correct) = a Days + b$
でも同じ。今度は Correct を0--1の外を許してあげている。

そこから <u>2. 確率の値に基づいて正誤(0/1)が生成される</u>
という結果となります。






ただ、
これはつまり、



$Y(非直線) ~ F(ax+b)$

つまり、一旦別の関数を噛ませて

直線でない

y=ax+b ではなく y=f(ax+b) を考える。
yには0や1,
ax+bには200など。
これを0--1の値に収める関数;
一旦収めると y=1の時に 0.2だったら変.
y=0の時に 0.8 だったら変。
そういう感じで aやbの値を更新できる。


カーブして欲しい。
これは0--1の連続

ここまでをまとめると

[u1]: ./1.html
[u2]: ./2.html
[u3]: ./3.html

[back](./)

---
